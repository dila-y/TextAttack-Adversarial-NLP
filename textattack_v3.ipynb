{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e84g1YoseoE"
      },
      "source": [
        "# TextAttack End-to-End\n",
        "\n",
        "This tutorial provides a broad end-to-end overview of training, evaluating, and attacking a model using [TextAttack](https://textattack.readthedocs.io/en/master/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONayD5EJseoG"
      },
      "source": [
        "## Training\n",
        "Text attack comes with its own fine tuned models on several datasets. You can list them with the command below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsPK2rqzdECn",
        "outputId": "c5f080d6-5ae1-4bbe-bde3-2166845420ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting textattack\n",
            "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting bert-score>=0.3.5 (from textattack)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.12/dist-packages (from textattack) (0.8.1)\n",
            "Collecting flair (from textattack)\n",
            "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from textattack) (3.20.0)\n",
            "Collecting language-tool-python (from textattack)\n",
            "  Downloading language_tool_python-2.9.4-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lemminflect (from textattack)\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting lru-dict (from textattack)\n",
            "  Downloading lru_dict-1.3.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: datasets>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from textattack) (4.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textattack) (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from textattack) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from textattack) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from textattack) (1.16.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from textattack) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from textattack) (4.57.0)\n",
            "Collecting terminaltables (from textattack)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from textattack) (4.67.1)\n",
            "Collecting word2number (from textattack)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from textattack)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from textattack) (10.8.0)\n",
            "Collecting pinyin>=0.4.0 (from textattack)\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (from textattack) (0.42.1)\n",
            "Collecting OpenHowNet (from textattack)\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score>=0.3.5->textattack) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score>=0.3.5->textattack) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score>=0.3.5->textattack) (25.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.4.0->textattack) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.4.0->textattack) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.4.0->textattack) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.4.0->textattack) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->textattack) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->textattack) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->textattack) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->textattack) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->textattack) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->textattack) (0.6.2)\n",
            "Collecting boto3>=1.20.27 (from flair->textattack)\n",
            "  Downloading boto3-1.40.50-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair->textattack)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting deprecated>=1.2.13 (from flair->textattack)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from flair->textattack) (5.2.0)\n",
            "Collecting langdetect>=1.0.9 (from flair->textattack)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from flair->textattack) (5.4.0)\n",
            "Collecting mpld3>=0.3 (from flair->textattack)\n",
            "  Downloading mpld3-0.5.11-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pptree>=3.1 (from flair->textattack)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from flair->textattack) (1.6.1)\n",
            "Collecting segtok>=1.5.11 (from flair->textattack)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.12/dist-packages (from flair->textattack) (0.9.0)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from language-tool-python->textattack) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from language-tool-python->textattack) (0.10.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textattack) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textattack) (1.5.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree (from OpenHowNet->textattack)\n",
            "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.41.0,>=1.40.50 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading botocore-1.40.50-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.17.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (3.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.14)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.4.0->flair->textattack) (4.13.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.4.0->textattack) (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect>=1.0.9->flair->textattack) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score>=0.3.5->textattack) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score>=0.3.5->textattack) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->textattack) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->textattack) (5.29.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.22.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.10.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.8)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
            "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_tool_python-2.9.4-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lru_dict-1.3.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.40.50-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.11-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading transformer_smaller_training_vocab-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.50-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pinyin, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=f54d1c999bb2f86b954940916fb74b29161feb1ec2121d35bfdf70ce2ba967bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/b9/d6/a01fdab49ff6237e81b0fceeb3a6a3c656733b58ba64c30ed7\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=da7b41561835559a47d9ad06e0acd4a4c1d293143d82e1cf8eea4995cf44404b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/79/fb/d25928e599c7e11fe4e00d32048cd74933f34a74c633d2aea6\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=4b343f65e822eb6b3d9fbdfcb3013e959ea49e46023c12a8af3cf02ceb6cb58f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=93889264732a97655b0ecad5fc232cff245c23baabc904d09d8e800deb08ee4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=1da4bc6414ac116281fc4356bdeebf7f9a36a5865f7a749a24793b10bf2b6037\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/2d/de/37058114a8f07cfec75747cb46b864bc5c71b0e9e0e4cd0acd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=e77218891f49de37e585e7f81e02d28d89e1422bf3a9d48eb145428ddce57997\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/6f/21/fc016aef45ffcabe27129a2252f061387cbf278d2086225a64\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=1be0244b7ec0d19a0d9d3a9f80ae8823f898363254b8fdcaaa7dc002aeb7c4bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/3c/79/b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=41e87df1c06fc20fb66a90acd7b7874f233b32e927907783d69f63caa264df4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/c3/c3/238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
            "Successfully built pinyin word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n",
            "Installing collected packages: word2number, sqlitedict, pptree, pinyin, docopt, terminaltables, segtok, num2words, lru-dict, lemminflect, langdetect, jsonlines, jmespath, intervaltree, ftfy, deprecated, conllu, anytree, wikipedia-api, OpenHowNet, language-tool-python, botocore, bioc, s3transfer, mpld3, pytorch-revgrad, boto3, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
            "Successfully installed OpenHowNet-2.0 anytree-2.13.0 bert-score-0.3.13 bioc-2.1 boto3-1.40.50 botocore-1.40.50 conllu-4.5.3 deprecated-1.2.18 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 language-tool-python-2.9.4 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.11 num2words-0.5.14 pinyin-0.4.0 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.14.0 segtok-1.5.11 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 transformer-smaller-training-vocab-0.4.2 wikipedia-api-0.8.1 word2number-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install textattack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQHh6boHaamH",
        "outputId": "7b5f408f-6bad-4a45-a8d1-ecd5cfc24416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.45.2\n",
            "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (0.6.2)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.2)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (2025.10.5)\n",
            "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.0\n",
            "    Uninstalling transformers-4.57.0:\n",
            "      Successfully uninstalled transformers-4.57.0\n",
            "Successfully installed tokenizers-0.20.3 transformers-4.45.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"transformers==4.45.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thVtyRTkGeFu",
        "outputId": "85f69da2-27f8-4a07-f78c-2329e56f801b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34;1mtextattack\u001b[0m: Updating TextAttack package dependencies.\n",
            "\u001b[34;1mtextattack\u001b[0m: Downloading NLTK required packages.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "2025-10-12 22:06:39.817247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760306799.837065    5982 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760306799.842920    5982 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760306799.859005    5982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760306799.859029    5982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760306799.859033    5982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760306799.859038    5982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n",
            "\u001b[94malbert-base-v2\u001b[0m\n",
            "\u001b[94malbert-base-v2-ag-news\u001b[0m\n",
            "\u001b[94malbert-base-v2-cola\u001b[0m\n",
            "\u001b[94malbert-base-v2-imdb\u001b[0m\n",
            "\u001b[94malbert-base-v2-mr\u001b[0m\n",
            "\u001b[94malbert-base-v2-qqp\u001b[0m\n",
            "\u001b[94malbert-base-v2-rte\u001b[0m\n",
            "\u001b[94malbert-base-v2-snli\u001b[0m\n",
            "\u001b[94malbert-base-v2-sst2\u001b[0m\n",
            "\u001b[94malbert-base-v2-stsb\u001b[0m\n",
            "\u001b[94malbert-base-v2-wnli\u001b[0m\n",
            "\u001b[94malbert-base-v2-yelp\u001b[0m\n",
            "\u001b[94mbert-base-uncased\u001b[0m\n",
            "\u001b[94mbert-base-uncased-ag-news\u001b[0m\n",
            "\u001b[94mbert-base-uncased-cola\u001b[0m\n",
            "\u001b[94mbert-base-uncased-imdb\u001b[0m\n",
            "\u001b[94mbert-base-uncased-mnli\u001b[0m\n",
            "\u001b[94mbert-base-uncased-mr\u001b[0m\n",
            "\u001b[94mbert-base-uncased-mrpc\u001b[0m\n",
            "\u001b[94mbert-base-uncased-qnli\u001b[0m\n",
            "\u001b[94mbert-base-uncased-qqp\u001b[0m\n",
            "\u001b[94mbert-base-uncased-rte\u001b[0m\n",
            "\u001b[94mbert-base-uncased-snli\u001b[0m\n",
            "\u001b[94mbert-base-uncased-sst2\u001b[0m\n",
            "\u001b[94mbert-base-uncased-stsb\u001b[0m\n",
            "\u001b[94mbert-base-uncased-wnli\u001b[0m\n",
            "\u001b[94mbert-base-uncased-yelp\u001b[0m\n",
            "\u001b[94mcnn-ag-news\u001b[0m\n",
            "\u001b[94mcnn-imdb\u001b[0m\n",
            "\u001b[94mcnn-mr\u001b[0m\n",
            "\u001b[94mcnn-sst2\u001b[0m\n",
            "\u001b[94mcnn-yelp\u001b[0m\n",
            "\u001b[94mdistilbert-base-cased-cola\u001b[0m\n",
            "\u001b[94mdistilbert-base-cased-mrpc\u001b[0m\n",
            "\u001b[94mdistilbert-base-cased-qqp\u001b[0m\n",
            "\u001b[94mdistilbert-base-cased-snli\u001b[0m\n",
            "\u001b[94mdistilbert-base-cased-sst2\u001b[0m\n",
            "\u001b[94mdistilbert-base-cased-stsb\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-ag-news\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-cola\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-imdb\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-mnli\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-mr\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-mrpc\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-qnli\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-rte\u001b[0m\n",
            "\u001b[94mdistilbert-base-uncased-wnli\u001b[0m\n",
            "\u001b[94mlstm-ag-news\u001b[0m\n",
            "\u001b[94mlstm-imdb\u001b[0m\n",
            "\u001b[94mlstm-mr\u001b[0m\n",
            "\u001b[94mlstm-sst2\u001b[0m\n",
            "\u001b[94mlstm-yelp\u001b[0m\n",
            "\u001b[94mroberta-base\u001b[0m\n",
            "\u001b[94mroberta-base-ag-news\u001b[0m\n",
            "\u001b[94mroberta-base-cola\u001b[0m\n",
            "\u001b[94mroberta-base-imdb\u001b[0m\n",
            "\u001b[94mroberta-base-mr\u001b[0m\n",
            "\u001b[94mroberta-base-mrpc\u001b[0m\n",
            "\u001b[94mroberta-base-qnli\u001b[0m\n",
            "\u001b[94mroberta-base-rte\u001b[0m\n",
            "\u001b[94mroberta-base-sst2\u001b[0m\n",
            "\u001b[94mroberta-base-stsb\u001b[0m\n",
            "\u001b[94mroberta-base-wnli\u001b[0m\n",
            "\u001b[94mt5-en-de\u001b[0m\n",
            "\u001b[94mt5-en-fr\u001b[0m\n",
            "\u001b[94mt5-en-ro\u001b[0m\n",
            "\u001b[94mt5-summarization\u001b[0m\n",
            "\u001b[94mxlnet-base-cased\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-cola\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-imdb\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-mr\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-mrpc\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-rte\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-stsb\u001b[0m\n",
            "\u001b[94mxlnet-base-cased-wnli\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!textattack list models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhNIugCuGegY"
      },
      "source": [
        "You can use these models as it is by referring to their name. However for the purpose of this practical we are going to train our model from scratch.\n",
        "\n",
        "TextAttack integrates directly with [transformers](https://github.com/huggingface/transformers/) and [datasets](https://github.com/huggingface/datasets) to train any of the `transformers` pre-trained models on datasets from `datasets`.\n",
        "\n",
        "Let's use the Rotten Tomatoes Movie Review dataset: it's relatively short, and showcases the key features of `textattack train`. Let's take a look at the dataset using `textattack peek-dataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spS2eW5WseoG",
        "outputId": "bcee1175-257c-44d2-af8b-55774ff1424a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 22:09:01.707892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760306941.739022    6665 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760306941.748550    6665 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760306941.771189    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760306941.771218    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760306941.771226    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760306941.771232    6665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Number of samples: \u001b[94m8530\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Number of words per input:\n",
            "\u001b[34;1mtextattack\u001b[0m: \ttotal:   \u001b[94m157755\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tmean:    \u001b[94m18.49\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tstd:     \u001b[94m8.58\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tmin:     \u001b[94m1\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tmax:     \u001b[94m51\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Dataset lowercased: \u001b[94mTrue\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: First sample:\n",
            "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Last sample:\n",
            "things really get weird , though not particularly scary : the movie is all portent and no content . \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Found 2 distinct outputs.\n",
            "\u001b[34;1mtextattack\u001b[0m: Most common outputs:\n",
            "\t 1      (4265)\n",
            "\t 0      (4265)\n"
          ]
        }
      ],
      "source": [
        "!textattack peek-dataset --dataset-from-huggingface rotten_tomatoes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uguqpjnLseoI"
      },
      "source": [
        "The dataset looks good! It's lowercased already, so we'll make sure our model is uncased. The longest input is 51 words, so we can cap our maximum sequence length (`--model-max-length`) at 64.\n",
        "\n",
        "We'll train [`distilbert-base-uncased`](https://huggingface.co/transformers/model_doc/distilbert.html), since it's a relatively small model, and a good example of how we integrate with `transformers`.\n",
        "\n",
        "So we have our command:\n",
        "\n",
        "```bash\n",
        "textattack train                      \\ # Train a model with TextAttack\n",
        "    --model distilbert-base-uncased   \\ # Using distilbert, uncased version, from `transformers`\n",
        "    --dataset rotten_tomatoes         \\ # On the Rotten Tomatoes dataset\n",
        "    --model-num-labels 2              \\ # That has 2 labels\n",
        "    --model-max-length 64             \\ # With a maximum sequence length of 64\n",
        "    --per-device-train-batch-size 128 \\ # And batch size of 128\n",
        "    --num-epochs 3                    \\ # For 3 epochs\n",
        "```\n",
        "\n",
        "Now let's run it (please remember to use GPU if you have access):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY33W9aWseoI",
        "outputId": "8cef9120-a1bb-450d-a752-3800b933dedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "2025-10-12 22:11:02.604081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760307062.623061    7298 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760307062.628859    7298 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760307062.643351    7298 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307062.643375    7298 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307062.643379    7298 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307062.643383    7298 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Writing logs to ./outputs/2025-10-12-22-11-09-041877/train_log.txt.\n",
            "\u001b[34;1mtextattack\u001b[0m: Wrote original training args to ./outputs/2025-10-12-22-11-09-041877/training_args.json.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n",
            "\u001b[34;1mtextattack\u001b[0m:   Num examples = 8530\n",
            "\u001b[34;1mtextattack\u001b[0m:   Num epochs = 3\n",
            "\u001b[34;1mtextattack\u001b[0m:   Num clean epochs = 3\n",
            "\u001b[34;1mtextattack\u001b[0m:   Instantaneous batch size per device = 128\n",
            "\u001b[34;1mtextattack\u001b[0m:   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "\u001b[34;1mtextattack\u001b[0m:   Gradient accumulation steps = 1\n",
            "\u001b[34;1mtextattack\u001b[0m:   Total optimization steps = 201\n",
            "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
            "\u001b[34;1mtextattack\u001b[0m: Epoch 1\n",
            "\u001b[34;1mtextattack\u001b[0m: Running clean epoch 1/3\n",
            "Loss 0.68351: 100% 67/67 [00:38<00:00,  1.75it/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 56.76%\n",
            "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 77.95%\n",
            "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2025-10-12-22-11-09-041877/best_model/\n",
            "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
            "\u001b[34;1mtextattack\u001b[0m: Epoch 2\n",
            "\u001b[34;1mtextattack\u001b[0m: Running clean epoch 2/3\n",
            "Loss 0.56918: 100% 67/67 [00:39<00:00,  1.70it/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 80.59%\n",
            "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 83.77%\n",
            "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2025-10-12-22-11-09-041877/best_model/\n",
            "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
            "\u001b[34;1mtextattack\u001b[0m: Epoch 3\n",
            "\u001b[34;1mtextattack\u001b[0m: Running clean epoch 3/3\n",
            "Loss 0.48892: 100% 67/67 [00:41<00:00,  1.62it/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 86.49%\n",
            "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 85.37%\n",
            "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2025-10-12-22-11-09-041877/best_model/\n",
            "\u001b[34;1mtextattack\u001b[0m: Wrote README to ./outputs/2025-10-12-22-11-09-041877/README.md.\n"
          ]
        }
      ],
      "source": [
        "!textattack train --model-name-or-path distilbert-base-uncased --dataset rotten_tomatoes --model-num-labels 2 --model-max-length 64 --per-device-train-batch-size 128 --num-epochs 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xzv3BGLseoI"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We successfully fine-tuned `distilbert-base-cased` for 3 epochs. Now let's evaluate it using `textattack eval`. This is as simple as providing the path to the pretrained model (that you just obtain from running the above command!) to `--model`, along with the number of evaluation samples. `textattack eval` will automatically load the evaluation data from training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGYR_W6DseoJ",
        "outputId": "0b07b272-d4ae-4bc3-e8de-aec832de1ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 22:14:35.322382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760307275.342503    8233 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760307275.348609    8233 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760307275.364567    8233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307275.364593    8233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307275.364598    8233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307275.364601    8233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Got 1000 predictions.\n",
            "\u001b[34;1mtextattack\u001b[0m: Correct 842/1000 (\u001b[94m84.20%\u001b[0m)\n"
          ]
        }
      ],
      "source": [
        "!textattack eval --num-examples 1000 --model ./outputs/2025-10-12-22-11-09-041877/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFPkCZShseoJ"
      },
      "source": [
        "Awesome -- we were able to train a model up to 84.4% accuracy on the test dataset – with only a single command!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWglEuvUseoK"
      },
      "source": [
        "## Attack\n",
        "\n",
        "Finally, let's attack our pre-trained model. We can do this the same way as before (by providing the path to the pretrained model to `--model`). For our attack, let's use the \"TextFooler\" attack recipe, from the paper [\"Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment\" (Jin et al, 2019)](https://arxiv.org/abs/1907.11932). We can do this by passing `--recipe textfooler` to `textattack attack`.\n",
        "\n",
        "> *Warning*: We're printing out 100 examples and, if the attack succeeds, their perturbations. The output of this command is going to be quite long!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IagTMxZygmzO",
        "outputId": "02d478c3-cd82-4dfd-b66d-48257ffa6872"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded NLTK resources.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')  \n",
        "nltk.download('punkt')                            \n",
        "nltk.download('wordnet'); nltk.download('omw-1.4')\n",
        "print(\"Downloaded NLTK resources.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL-Bo1bgseoK",
        "outputId": "c1ff5ca6-02f4-4809-fddc-d21e77f49fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 23:00:07.606239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760310007.626257   20090 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760310007.632412   20090 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760310007.647682   20090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760310007.647707   20090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760310007.647711   20090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760310007.647715   20090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]2025-10-12 23:00:24.394024: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1760310024.394209   20090 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13576 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "  1% 1/100 [00:09<15:35,  9.45s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (65%)\u001b[0m\n",
            "\n",
            "\u001b[92mlovingly\u001b[0m photographed in the manner of a golden book sprung to life , stuart little 2 manages \u001b[92msweetness\u001b[0m largely without stickiness .\n",
            "\n",
            "\u001b[91mclumsily\u001b[0m photographed in the manner of a golden book sprung to life , stuart little 2 manages \u001b[91mhoneyed\u001b[0m largely without stickiness .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   2% 2/100 [00:09<08:01,  4.92s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
            "\n",
            "\u001b[92mconsistently\u001b[0m \u001b[92mclever\u001b[0m and \u001b[92msuspenseful\u001b[0m .\n",
            "\n",
            "\u001b[91mceaselessly\u001b[0m \u001b[91mmalin\u001b[0m and \u001b[91mmelodramatic\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:   2% 2/100 [00:09<08:02,  4.92s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[91mNegative (88%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 1 / 3:   4% 4/100 [00:10<04:01,  2.51s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
            "\n",
            "the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with \u001b[92mtremendous\u001b[0m \u001b[92mskill\u001b[0m .\n",
            "\n",
            "the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with \u001b[91mstupendous\u001b[0m \u001b[91mcompetency\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 1 / 4:   4% 4/100 [00:10<04:01,  2.52s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (68%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "red dragon \" never cuts corners .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   6% 6/100 [00:10<02:39,  1.70s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mPositive (62%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
            "\n",
            "fresnadillo has something serious to say about the \u001b[92mways\u001b[0m in which extravagant chance can distort our perspective and throw us off the path of good sense .\n",
            "\n",
            "fresnadillo has something serious to say about the \u001b[91mmanner\u001b[0m in which extravagant chance can distort our perspective and throw us off the path of good sense .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 2 / 6:   6% 6/100 [00:10<02:40,  1.70s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (74%)\u001b[0m\n",
            "\n",
            "throws in enough clever and \u001b[92munexpected\u001b[0m \u001b[92mtwists\u001b[0m to make the formula feel fresh .\n",
            "\n",
            "throws in enough clever and \u001b[91munwanted\u001b[0m \u001b[91mtendrils\u001b[0m to make the formula feel fresh .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 2 / 7:   8% 8/100 [00:10<01:59,  1.30s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91mNegative (62%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "weighty and ponderous but every bit as filling as the treat of the title .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 3 / 8:   8% 8/100 [00:10<01:59,  1.30s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "a \u001b[92mreal\u001b[0m audience-pleaser that will \u001b[92mstrike\u001b[0m a \u001b[92mchord\u001b[0m with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
            "\n",
            "a \u001b[91mactual\u001b[0m audience-pleaser that will \u001b[91mslugged\u001b[0m a \u001b[91mchords\u001b[0m with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 3 / 9:  10% 10/100 [00:10<01:38,  1.09s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (95%)\u001b[0m\n",
            "\n",
            "generates an \u001b[92menormous\u001b[0m \u001b[92mfeeling\u001b[0m of empathy for its characters .\n",
            "\n",
            "generates an \u001b[91mdreaded\u001b[0m \u001b[91mpremonition\u001b[0m of empathy for its characters .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 3 / 10:  10% 10/100 [00:10<01:38,  1.09s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (92%)\u001b[0m\n",
            "\n",
            "exposing the \u001b[92mways\u001b[0m we fool ourselves is one hour photo's real \u001b[92mstrength\u001b[0m .\n",
            "\n",
            "exposing the \u001b[91mrouting\u001b[0m we fool ourselves is one hour photo's real \u001b[91mstrenght\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 3 / 11:  12% 12/100 [00:11<01:23,  1.06it/s]--------------------------------------------- Result 12 ---------------------------------------------\n",
            "\u001b[92mPositive (68%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful \u001b[92mview\u001b[0m of american life .\n",
            "\n",
            "it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful \u001b[91mconsults\u001b[0m of american life .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 3 / 12:  12% 12/100 [00:11<01:23,  1.06it/s]--------------------------------------------- Result 13 ---------------------------------------------\n",
            "\u001b[91mNegative (84%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "mostly , [goldbacher] just lets her complicated characters be unruly , confusing and , through it all , human .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 4 / 13:  14% 14/100 [00:11<01:10,  1.22it/s]--------------------------------------------- Result 14 ---------------------------------------------\n",
            "\u001b[92mPositive (82%)\u001b[0m --> \u001b[91mNegative (97%)\u001b[0m\n",
            "\n",
            ". . . \u001b[92mquite\u001b[0m good at providing some good old fashioned spooks .\n",
            "\n",
            ". . . \u001b[91mtoo\u001b[0m good at providing some good old fashioned spooks .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 4 / 14:  14% 14/100 [00:11<01:10,  1.22it/s]--------------------------------------------- Result 15 ---------------------------------------------\n",
            "\u001b[91mNegative (95%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "at its worst , the movie is pretty diverting ; the pity is that it rarely achieves its best .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 5 / 15:  16% 16/100 [00:12<01:03,  1.32it/s]--------------------------------------------- Result 16 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (92%)\u001b[0m\n",
            "\n",
            "scherfig's light-hearted \u001b[92mprofile\u001b[0m of \u001b[92memotional\u001b[0m \u001b[92mdesperation\u001b[0m is achingly \u001b[92mhonest\u001b[0m and \u001b[92mdelightfully\u001b[0m \u001b[92mcheeky\u001b[0m .\n",
            "\n",
            "scherfig's light-hearted \u001b[91mdescription\u001b[0m of \u001b[91maffectionate\u001b[0m \u001b[91mdiscouragement\u001b[0m is achingly \u001b[91mcordial\u001b[0m and \u001b[91mblithely\u001b[0m \u001b[91mbratty\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 5 / 16:  16% 16/100 [00:12<01:03,  1.32it/s]--------------------------------------------- Result 17 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
            "\n",
            "a \u001b[92mjourney\u001b[0m \u001b[92mspanning\u001b[0m nearly three decades of bittersweet camaraderie and history , in which we feel that we truly know what makes holly and marina tick , and our \u001b[92mhearts\u001b[0m go out to them as both continue to negotiate their \u001b[92mimperfect\u001b[0m , love-hate relationship .\n",
            "\n",
            "a \u001b[91mtrekking\u001b[0m \u001b[91mexpectancy\u001b[0m nearly three decades of bittersweet camaraderie and history , in which we feel that we truly know what makes holly and marina tick , and our \u001b[91mcardiology\u001b[0m go out to them as both continue to negotiate their \u001b[91minsufficient\u001b[0m , love-hate relationship .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 12 / 0 / 5 / 17:  18% 18/100 [00:12<00:58,  1.40it/s]--------------------------------------------- Result 18 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (67%)\u001b[0m\n",
            "\n",
            "the \u001b[92mwonderfully\u001b[0m \u001b[92mlush\u001b[0m morvern callar is pure punk existentialism , and ms . ramsay and her co-writer , liana dognini , have dramatized the alan warner novel , which itself felt like an answer to irvine welsh's book trainspotting .\n",
            "\n",
            "the \u001b[91mappallingly\u001b[0m \u001b[91mlanguid\u001b[0m morvern callar is pure punk existentialism , and ms . ramsay and her co-writer , liana dognini , have dramatized the alan warner novel , which itself felt like an answer to irvine welsh's book trainspotting .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 13 / 0 / 5 / 18:  18% 18/100 [00:12<00:58,  1.40it/s]--------------------------------------------- Result 19 ---------------------------------------------\n",
            "\u001b[92mPositive (60%)\u001b[0m --> \u001b[91mNegative (67%)\u001b[0m\n",
            "\n",
            "as it \u001b[92mturns\u001b[0m out , you can go \u001b[92mhome\u001b[0m again .\n",
            "\n",
            "as it \u001b[91mswivel\u001b[0m out , you can go \u001b[91mhousework\u001b[0m again .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 14 / 0 / 5 / 19:  20% 20/100 [00:13<00:52,  1.53it/s]--------------------------------------------- Result 20 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (77%)\u001b[0m\n",
            "\n",
            "you've already seen city by the sea under a variety of titles , but it's \u001b[92mworth\u001b[0m yet another visit .\n",
            "\n",
            "you've already seen city by the sea under a variety of titles , but it's \u001b[91mchastisement\u001b[0m yet another visit .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 15 / 0 / 5 / 20:  20% 20/100 [00:13<00:52,  1.53it/s]--------------------------------------------- Result 21 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
            "\n",
            "this kind of hands-on \u001b[92mstorytelling\u001b[0m is ultimately what \u001b[92mmakes\u001b[0m shanghai ghetto move beyond a \u001b[92mgood\u001b[0m , dry , reliable textbook and what allows it to rank with its \u001b[92mworthy\u001b[0m predecessors .\n",
            "\n",
            "this kind of hands-on \u001b[91mmyth\u001b[0m is ultimately what \u001b[91mdo\u001b[0m shanghai ghetto move beyond a \u001b[91msuitable\u001b[0m , dry , reliable textbook and what allows it to rank with its \u001b[91mlegitimate\u001b[0m predecessors .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 16 / 0 / 5 / 21:  22% 22/100 [00:13<00:48,  1.62it/s]--------------------------------------------- Result 22 ---------------------------------------------\n",
            "\u001b[92mPositive (69%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
            "\n",
            "making such a tragedy the backdrop to a love story risks trivializing it , though chouraqui no doubt intended the film to affirm love's power to \u001b[92mhelp\u001b[0m people endure almost unimaginable horror .\n",
            "\n",
            "making such a tragedy the backdrop to a love story risks trivializing it , though chouraqui no doubt intended the film to affirm love's power to \u001b[91msuccor\u001b[0m people endure almost unimaginable horror .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 17 / 0 / 5 / 22:  22% 22/100 [00:13<00:48,  1.62it/s]--------------------------------------------- Result 23 ---------------------------------------------\n",
            "\u001b[91mNegative (58%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "grown-up quibbles are beside the point here . the little girls understand , and mccracken knows that's all that matters .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 17 / 0 / 6 / 23:  24% 24/100 [00:13<00:43,  1.74it/s]--------------------------------------------- Result 24 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (64%)\u001b[0m\n",
            "\n",
            "a \u001b[92mpowerful\u001b[0m , \u001b[92mchilling\u001b[0m , and affecting study of one man's dying fall .\n",
            "\n",
            "a \u001b[91mpompous\u001b[0m , \u001b[91mdeterrent\u001b[0m , and affecting study of one man's dying fall .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 18 / 0 / 6 / 24:  24% 24/100 [00:13<00:43,  1.74it/s]--------------------------------------------- Result 25 ---------------------------------------------\n",
            "\u001b[92mPositive (74%)\u001b[0m --> \u001b[91mNegative (86%)\u001b[0m\n",
            "\n",
            "this is a \u001b[92mfascinating\u001b[0m film because there is no clear-cut hero and no all-out villain .\n",
            "\n",
            "this is a \u001b[91mastounding\u001b[0m film because there is no clear-cut hero and no all-out villain .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 19 / 0 / 6 / 25:  26% 26/100 [00:13<00:39,  1.86it/s]--------------------------------------------- Result 26 ---------------------------------------------\n",
            "\u001b[92mPositive (83%)\u001b[0m --> \u001b[91mNegative (81%)\u001b[0m\n",
            "\n",
            "a dreadful day in irish history is given \u001b[92mpassionate\u001b[0m , if somewhat flawed , treatment .\n",
            "\n",
            "a dreadful day in irish history is given \u001b[91mgreedy\u001b[0m , if somewhat flawed , treatment .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 20 / 0 / 6 / 26:  26% 26/100 [00:13<00:39,  1.86it/s]--------------------------------------------- Result 27 ---------------------------------------------\n",
            "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
            "\n",
            ". . . a \u001b[92mgood\u001b[0m film that must have baffled the folks in the marketing department .\n",
            "\n",
            ". . . a \u001b[91mok\u001b[0m film that must have baffled the folks in the marketing department .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 21 / 0 / 6 / 27:  28% 28/100 [00:14<00:36,  1.95it/s]--------------------------------------------- Result 28 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
            "\n",
            ". . . is \u001b[92mfunny\u001b[0m in the \u001b[92mway\u001b[0m that makes you ache with sadness ( the way chekhov is funny ) , \u001b[92mprofound\u001b[0m without ever being self-important , \u001b[92mwarm\u001b[0m without ever succumbing to sentimentality .\n",
            "\n",
            ". . . is \u001b[91mjest\u001b[0m in the \u001b[91mmethodology\u001b[0m that makes you ache with sadness ( the way chekhov is funny ) , \u001b[91mshum\u001b[0m without ever being self-important , \u001b[91mtepid\u001b[0m without ever succumbing to sentimentality .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 22 / 0 / 6 / 28:  28% 28/100 [00:14<00:36,  1.95it/s]--------------------------------------------- Result 29 ---------------------------------------------\n",
            "\u001b[91mNegative (96%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "devotees of star trek ii : the wrath of khan will feel a nagging sense of deja vu , and the grandeur of the best next generation episodes is lacking .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 22 / 0 / 7 / 29:  30% 30/100 [00:15<00:35,  1.99it/s]--------------------------------------------- Result 30 ---------------------------------------------\n",
            "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "a soul-stirring documentary about the israeli/palestinian conflict as revealed through the eyes of some children who remain curious about each other against all odds .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 22 / 1 / 7 / 30:  30% 30/100 [00:15<00:35,  1.99it/s]--------------------------------------------- Result 31 ---------------------------------------------\n",
            "\u001b[92mPositive (72%)\u001b[0m --> \u001b[91mNegative (81%)\u001b[0m\n",
            "\n",
            "what's so \u001b[92mstriking\u001b[0m about jolie's performance is that she never lets her character become a caricature -- not even with that radioactive hair .\n",
            "\n",
            "what's so \u001b[91mstaggering\u001b[0m about jolie's performance is that she never lets her character become a caricature -- not even with that radioactive hair .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 1 / 7 / 31:  31% 31/100 [00:15<00:33,  2.04it/s]--------------------------------------------- Result 32 ---------------------------------------------\n",
            "\u001b[91mNegative (82%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "the main story . . . is compelling enough , but it's difficult to shrug off the annoyance of that chatty fish .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 1 / 8 / 32:  33% 33/100 [00:15<00:30,  2.17it/s]--------------------------------------------- Result 33 ---------------------------------------------\n",
            "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (92%)\u001b[0m\n",
            "\n",
            "the performances are \u001b[92mimmaculate\u001b[0m , with roussillon providing comic relief .\n",
            "\n",
            "the performances are \u001b[91mfaultless\u001b[0m , with roussillon providing comic relief .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 24 / 1 / 8 / 33:  33% 33/100 [00:15<00:30,  2.16it/s]--------------------------------------------- Result 34 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (81%)\u001b[0m\n",
            "\n",
            "kinnear . . . \u001b[92mgives\u001b[0m his best screen performance with an \u001b[92moddly\u001b[0m \u001b[92mwinning\u001b[0m \u001b[92mportrayal\u001b[0m of one of life's \u001b[92multimate\u001b[0m losers .\n",
            "\n",
            "kinnear . . . \u001b[91massigns\u001b[0m his best screen performance with an \u001b[91mridiculously\u001b[0m \u001b[91mearns\u001b[0m \u001b[91msimilarity\u001b[0m of one of life's \u001b[91mfinale\u001b[0m losers .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 25 / 1 / 8 / 34:  34% 34/100 [00:15<00:30,  2.17it/s]--------------------------------------------- Result 35 ---------------------------------------------\n",
            "\u001b[91mNegative (59%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "hugh grant , who has a good line in charm , has never been more charming than in about a boy .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 25 / 1 / 9 / 35:  36% 36/100 [00:15<00:28,  2.28it/s]--------------------------------------------- Result 36 ---------------------------------------------\n",
            "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (86%)\u001b[0m\n",
            "\n",
            "there's a lot of tooth in roger dodger . but what's \u001b[92mnice\u001b[0m is that there's a casual intelligence that permeates the script .\n",
            "\n",
            "there's a lot of tooth in roger dodger . but what's \u001b[91mleggy\u001b[0m is that there's a casual intelligence that permeates the script .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 26 / 1 / 9 / 36:  36% 36/100 [00:15<00:28,  2.28it/s]--------------------------------------------- Result 37 ---------------------------------------------\n",
            "\u001b[91mNegative (73%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "reminiscent of alfred hitchcock's thrillers , most of the scary parts in 'signs' occur while waiting for things to happen .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 26 / 1 / 10 / 37:  37% 37/100 [00:15<00:26,  2.34it/s]--------------------------------------------- Result 38 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
            "\n",
            "one of the \u001b[92mbest\u001b[0m looking and \u001b[92mstylish\u001b[0m \u001b[92manimated\u001b[0m movies in quite a while . . .\n",
            "\n",
            "one of the \u001b[91mstrictest\u001b[0m looking and \u001b[91mfashionable\u001b[0m \u001b[91mabetted\u001b[0m movies in quite a while . . .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 27 / 1 / 10 / 38:  39% 39/100 [00:16<00:25,  2.41it/s]--------------------------------------------- Result 39 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
            "\n",
            "its use of the thriller form to examine the labyrinthine ways in which people's lives cross and change , buffeted by events seemingly out of their control , is \u001b[92mintriguing\u001b[0m , \u001b[92mprovocative\u001b[0m stuff .\n",
            "\n",
            "its use of the thriller form to examine the labyrinthine ways in which people's lives cross and change , buffeted by events seemingly out of their control , is \u001b[91mbaffling\u001b[0m , \u001b[91mincite\u001b[0m stuff .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 28 / 1 / 10 / 39:  39% 39/100 [00:16<00:25,  2.41it/s]--------------------------------------------- Result 40 ---------------------------------------------\n",
            "\u001b[92mPositive (89%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "denver \u001b[92mshould\u001b[0m not get the first and last look at one of the most triumphant performances of vanessa redgrave's career . it deserves to be seen everywhere .\n",
            "\n",
            "denver \u001b[91mwoud\u001b[0m not get the first and last look at one of the most triumphant performances of vanessa redgrave's career . it deserves to be seen everywhere .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 29 / 1 / 10 / 40:  40% 40/100 [00:16<00:24,  2.46it/s]--------------------------------------------- Result 41 ---------------------------------------------\n",
            "\u001b[92mPositive (60%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
            "\n",
            "you needn't be steeped in '50s sociology , pop culture or movie lore to appreciate the emotional depth of haynes' work . \u001b[92mthough\u001b[0m haynes' style apes films from the period . . . its message is not rooted in that decade .\n",
            "\n",
            "you needn't be steeped in '50s sociology , pop culture or movie lore to appreciate the emotional depth of haynes' work . \u001b[91malbeit\u001b[0m haynes' style apes films from the period . . . its message is not rooted in that decade .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 30 / 1 / 10 / 41:  42% 42/100 [00:16<00:22,  2.55it/s]--------------------------------------------- Result 42 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (70%)\u001b[0m\n",
            "\n",
            "waiting for godard can be \u001b[92mfruitful\u001b[0m : 'in praise of love' is the director's epitaph for himself .\n",
            "\n",
            "waiting for godard can be \u001b[91msalubrious\u001b[0m : 'in praise of love' is the director's epitaph for himself .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 31 / 1 / 10 / 42:  42% 42/100 [00:16<00:22,  2.55it/s]--------------------------------------------- Result 43 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (92%)\u001b[0m\n",
            "\n",
            "a gangster movie with the capacity to \u001b[92msurprise\u001b[0m .\n",
            "\n",
            "a gangster movie with the capacity to \u001b[91mstupor\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 32 / 1 / 10 / 43:  43% 43/100 [00:16<00:22,  2.59it/s]--------------------------------------------- Result 44 ---------------------------------------------\n",
            "\u001b[92mPositive (67%)\u001b[0m --> \u001b[91mNegative (91%)\u001b[0m\n",
            "\n",
            "the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are \u001b[92mworth\u001b[0m the price of admission . . . if \" gory mayhem \" is your idea of a good time .\n",
            "\n",
            "the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are \u001b[91mpriceless\u001b[0m the price of admission . . . if \" gory mayhem \" is your idea of a good time .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 33 / 1 / 10 / 44:  45% 45/100 [00:16<00:20,  2.68it/s]--------------------------------------------- Result 45 ---------------------------------------------\n",
            "\u001b[92mPositive (53%)\u001b[0m --> \u001b[91mNegative (85%)\u001b[0m\n",
            "\n",
            "if not a home run , then at least a \u001b[92msolid\u001b[0m base hit .\n",
            "\n",
            "if not a home run , then at least a \u001b[91mbeefy\u001b[0m base hit .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 34 / 1 / 10 / 45:  45% 45/100 [00:16<00:20,  2.68it/s]--------------------------------------------- Result 46 ---------------------------------------------\n",
            "\u001b[92mPositive (84%)\u001b[0m --> \u001b[91mNegative (79%)\u001b[0m\n",
            "\n",
            "goldmember is \u001b[92mfunny\u001b[0m enough to justify the embarrassment of bringing a barf bag to the moviehouse .\n",
            "\n",
            "goldmember is \u001b[91mcomical\u001b[0m enough to justify the embarrassment of bringing a barf bag to the moviehouse .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 35 / 1 / 10 / 46:  46% 46/100 [00:16<00:19,  2.72it/s]--------------------------------------------- Result 47 ---------------------------------------------\n",
            "\u001b[92mPositive (88%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
            "\n",
            ". . . a fairly disposable yet still \u001b[92mentertaining\u001b[0m b picture .\n",
            "\n",
            ". . . a fairly disposable yet still \u001b[91mdroll\u001b[0m b picture .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 36 / 1 / 10 / 47:  48% 48/100 [00:17<00:18,  2.76it/s]--------------------------------------------- Result 48 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (76%)\u001b[0m\n",
            "\n",
            "it may not be particularly \u001b[92minnovative\u001b[0m , but the film's crisp , \u001b[92munaffected\u001b[0m style and air of gentle \u001b[92mlonging\u001b[0m \u001b[92mmake\u001b[0m it unexpectedly \u001b[92mrewarding\u001b[0m .\n",
            "\n",
            "it may not be particularly \u001b[91munpublished\u001b[0m , but the film's crisp , \u001b[91munaltered\u001b[0m style and air of gentle \u001b[91mvacuuming\u001b[0m \u001b[91mdoing\u001b[0m it unexpectedly \u001b[91mbounties\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 37 / 1 / 10 / 48:  48% 48/100 [00:17<00:18,  2.76it/s]--------------------------------------------- Result 49 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (81%)\u001b[0m\n",
            "\n",
            "the film \u001b[92mtruly\u001b[0m does rescue [the funk brothers] from motown's shadows . it's about time .\n",
            "\n",
            "the film \u001b[91mawfully\u001b[0m does rescue [the funk brothers] from motown's shadows . it's about time .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 38 / 1 / 10 / 49:  49% 49/100 [00:17<00:18,  2.80it/s]--------------------------------------------- Result 50 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
            "\n",
            "drawing on an \u001b[92mirresistible\u001b[0m , languid romanticism , byler \u001b[92mreveals\u001b[0m the \u001b[92mways\u001b[0m in which a sultry evening or a beer-fueled afternoon in the sun can inspire even the most retiring heart to venture forth .\n",
            "\n",
            "drawing on an \u001b[91mstupendous\u001b[0m , languid romanticism , byler \u001b[91mbetrays\u001b[0m the \u001b[91mmenu\u001b[0m in which a sultry evening or a beer-fueled afternoon in the sun can inspire even the most retiring heart to venture forth .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 39 / 1 / 10 / 50:  51% 51/100 [00:17<00:17,  2.86it/s]--------------------------------------------- Result 51 ---------------------------------------------\n",
            "\u001b[91mNegative (90%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 39 / 1 / 11 / 51:  51% 51/100 [00:17<00:17,  2.86it/s]--------------------------------------------- Result 52 ---------------------------------------------\n",
            "\u001b[92mPositive (66%)\u001b[0m --> \u001b[91mNegative (65%)\u001b[0m\n",
            "\n",
            "[scherfig] has made a \u001b[92mmovie\u001b[0m that will leave you wondering about the characters' lives after the \u001b[92mclever\u001b[0m credits roll .\n",
            "\n",
            "[scherfig] has made a \u001b[91mcine\u001b[0m that will leave you wondering about the characters' lives after the \u001b[91msmarter\u001b[0m credits roll .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 40 / 1 / 11 / 52:  52% 52/100 [00:17<00:16,  2.89it/s]--------------------------------------------- Result 53 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "a \u001b[92mheady\u001b[0m , \u001b[92mbiting\u001b[0m , be-bop ride through nighttime manhattan , a loquacious videologue of the \u001b[92mmodern\u001b[0m male and the lengths to which he'll go to \u001b[92mweave\u001b[0m a protective cocoon around his own ego .\n",
            "\n",
            "a \u001b[91mdisordered\u001b[0m , \u001b[91mgnawing\u001b[0m , be-bop ride through nighttime manhattan , a loquacious videologue of the \u001b[91mupgraded\u001b[0m male and the lengths to which he'll go to \u001b[91msewn\u001b[0m a protective cocoon around his own ego .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 41 / 1 / 11 / 53:  54% 54/100 [00:18<00:15,  2.94it/s]--------------------------------------------- Result 54 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (68%)\u001b[0m\n",
            "\n",
            "skin of man gets a few cheap shocks from its kids-in-peril theatrics , but it also \u001b[92mtaps\u001b[0m into the \u001b[92mprimal\u001b[0m fears of young people trying to cope with the mysterious and brutal nature of adults .\n",
            "\n",
            "skin of man gets a few cheap shocks from its kids-in-peril theatrics , but it also \u001b[91mfaucets\u001b[0m into the \u001b[91mrudimentary\u001b[0m fears of young people trying to cope with the mysterious and brutal nature of adults .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 42 / 1 / 11 / 54:  54% 54/100 [00:18<00:15,  2.94it/s]--------------------------------------------- Result 55 ---------------------------------------------\n",
            "\u001b[92mPositive (87%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a \u001b[92mcool\u001b[0m distance from its material that is deliberately unsettling .\n",
            "\n",
            "the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a \u001b[91mcopacetic\u001b[0m distance from its material that is deliberately unsettling .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 43 / 1 / 11 / 55:  55% 55/100 [00:18<00:15,  2.98it/s]--------------------------------------------- Result 56 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
            "\n",
            "as \u001b[92mrefreshing\u001b[0m as a drink from a woodland stream .\n",
            "\n",
            "as \u001b[91mretrofit\u001b[0m as a drink from a woodland stream .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 44 / 1 / 11 / 56:  57% 57/100 [00:18<00:14,  3.05it/s]--------------------------------------------- Result 57 ---------------------------------------------\n",
            "\u001b[92mPositive (53%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
            "\n",
            "williams absolutely nails sy's queasy infatuation and overall \u001b[92mstrangeness\u001b[0m .\n",
            "\n",
            "williams absolutely nails sy's queasy infatuation and overall \u001b[91mennui\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 45 / 1 / 11 / 57:  57% 57/100 [00:18<00:14,  3.05it/s]--------------------------------------------- Result 58 ---------------------------------------------\n",
            "\u001b[92mPositive (64%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "can i admit xxx is as deep as a petri dish and as well-characterized as a telephone book but still say it was a guilty \u001b[92mpleasure\u001b[0m ?\n",
            "\n",
            "can i admit xxx is as deep as a petri dish and as well-characterized as a telephone book but still say it was a guilty \u001b[91mamusement\u001b[0m ?\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 46 / 1 / 11 / 58:  58% 58/100 [00:18<00:13,  3.09it/s]--------------------------------------------- Result 59 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (82%)\u001b[0m\n",
            "\n",
            "while it's nothing we haven't seen before from murphy , i spy is still \u001b[92mfun\u001b[0m and \u001b[92menjoyable\u001b[0m and so aggressively silly that it's more than a worthwhile effort .\n",
            "\n",
            "while it's nothing we haven't seen before from murphy , i spy is still \u001b[91mamusement\u001b[0m and \u001b[91mcosy\u001b[0m and so aggressively silly that it's more than a worthwhile effort .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 47 / 1 / 11 / 59:  60% 60/100 [00:18<00:12,  3.17it/s]--------------------------------------------- Result 60 ---------------------------------------------\n",
            "\u001b[91mNegative (65%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "by the time it ends in a rush of sequins , flashbulbs , blaring brass and back-stabbing babes , it has said plenty about how show business has infiltrated every corner of society -- and not always for the better .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 47 / 1 / 12 / 60:  60% 60/100 [00:18<00:12,  3.17it/s]--------------------------------------------- Result 61 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (85%)\u001b[0m\n",
            "\n",
            "an \u001b[92mintimate\u001b[0m contemplation of two marvelously messy lives .\n",
            "\n",
            "an \u001b[91msqueamish\u001b[0m contemplation of two marvelously messy lives .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 48 / 1 / 12 / 61:  61% 61/100 [00:19<00:12,  3.21it/s]--------------------------------------------- Result 62 ---------------------------------------------\n",
            "\u001b[91mNegative (60%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "rarely has skin looked as beautiful , desirable , even delectable , as it does in trouble every day .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 48 / 1 / 13 / 62:  63% 63/100 [00:19<00:11,  3.24it/s]--------------------------------------------- Result 63 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (59%)\u001b[0m\n",
            "\n",
            "this is one of those rare docs that \u001b[92mpaints\u001b[0m a \u001b[92mgrand\u001b[0m picture of an \u001b[92mera\u001b[0m and \u001b[92mmakes\u001b[0m the journey feel like a \u001b[92mparty\u001b[0m .\n",
            "\n",
            "this is one of those rare docs that \u001b[91mpaint\u001b[0m a \u001b[91mgargantuan\u001b[0m picture of an \u001b[91mduration\u001b[0m and \u001b[91mai\u001b[0m the journey feel like a \u001b[91mteil\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 49 / 1 / 13 / 63:  63% 63/100 [00:19<00:11,  3.24it/s]--------------------------------------------- Result 64 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
            "\n",
            "\u001b[92mpoignant\u001b[0m if familiar story of a young person suspended between two cultures .\n",
            "\n",
            "\u001b[91mdisquieting\u001b[0m if familiar story of a young person suspended between two cultures .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 50 / 1 / 13 / 64:  64% 64/100 [00:19<00:10,  3.27it/s]--------------------------------------------- Result 65 ---------------------------------------------\n",
            "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
            "\n",
            "a \u001b[92mmetaphor\u001b[0m for a modern-day urban china searching for its identity .\n",
            "\n",
            "a \u001b[91mcliché\u001b[0m for a modern-day urban china searching for its identity .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 51 / 1 / 13 / 65:  66% 66/100 [00:19<00:10,  3.34it/s]--------------------------------------------- Result 66 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (66%)\u001b[0m\n",
            "\n",
            "for all its brooding quality , ash wednesday is \u001b[92msuspenseful\u001b[0m and ultimately unpredictable , with a \u001b[92msterling\u001b[0m ensemble cast .\n",
            "\n",
            "for all its brooding quality , ash wednesday is \u001b[91mcliffhanger\u001b[0m and ultimately unpredictable , with a \u001b[91mstirling\u001b[0m ensemble cast .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 52 / 1 / 13 / 66:  66% 66/100 [00:19<00:10,  3.34it/s]--------------------------------------------- Result 67 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "an odd \u001b[92mdrama\u001b[0m set in the \u001b[92mworld\u001b[0m of lingerie models and bar dancers in the midwest that held my interest precisely because it didn't try to .\n",
            "\n",
            "an odd \u001b[91mtragedy\u001b[0m set in the \u001b[91mplanet\u001b[0m of lingerie models and bar dancers in the midwest that held my interest precisely because it didn't try to .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 53 / 1 / 13 / 67:  67% 67/100 [00:19<00:09,  3.36it/s]--------------------------------------------- Result 68 ---------------------------------------------\n",
            "\u001b[92mPositive (77%)\u001b[0m --> \u001b[91mNegative (63%)\u001b[0m\n",
            "\n",
            "the film feels uncomfortably real , its language and locations bearing the \u001b[92munmistakable\u001b[0m stamp of authority .\n",
            "\n",
            "the film feels uncomfortably real , its language and locations bearing the \u001b[91mdiscernible\u001b[0m stamp of authority .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 54 / 1 / 13 / 68:  69% 69/100 [00:20<00:09,  3.44it/s]--------------------------------------------- Result 69 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
            "\n",
            "despite its faults , gangs \u001b[92mexcels\u001b[0m in spectacle and pacing .\n",
            "\n",
            "despite its faults , gangs \u001b[91moverwhelms\u001b[0m in spectacle and pacing .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 55 / 1 / 13 / 69:  69% 69/100 [00:20<00:09,  3.43it/s]--------------------------------------------- Result 70 ---------------------------------------------\n",
            "\u001b[92mPositive (78%)\u001b[0m --> \u001b[91mNegative (69%)\u001b[0m\n",
            "\n",
            "\u001b[92mentertaining\u001b[0m despite its one-joke premise with the thesis that women from venus and men from mars can indeed get together .\n",
            "\n",
            "\u001b[91mamusement\u001b[0m despite its one-joke premise with the thesis that women from venus and men from mars can indeed get together .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 56 / 1 / 13 / 70:  70% 70/100 [00:20<00:08,  3.47it/s]--------------------------------------------- Result 71 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
            "\n",
            "a tightly directed , \u001b[92mhighly\u001b[0m professional film that's old-fashioned in all the best possible ways .\n",
            "\n",
            "a tightly directed , \u001b[91mexcessively\u001b[0m professional film that's old-fashioned in all the best possible ways .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 57 / 1 / 13 / 71:  72% 72/100 [00:20<00:08,  3.46it/s]--------------------------------------------- Result 72 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "it's \u001b[92mdark\u001b[0m but has \u001b[92mwonderfully\u001b[0m \u001b[92mfunny\u001b[0m \u001b[92mmoments\u001b[0m ; you \u001b[92mcare\u001b[0m about the characters ; and the \u001b[92maction\u001b[0m and special effects are first-rate .\n",
            "\n",
            "it's \u001b[91mdismal\u001b[0m but has \u001b[91munspeakably\u001b[0m \u001b[91mcomedy\u001b[0m \u001b[91mdated\u001b[0m ; you \u001b[91mzorg\u001b[0m about the characters ; and the \u001b[91moperating\u001b[0m and special effects are first-rate .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 58 / 1 / 13 / 72:  72% 72/100 [00:20<00:08,  3.46it/s]--------------------------------------------- Result 73 ---------------------------------------------\n",
            "\u001b[92mPositive (86%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "in visual fertility treasure planet rivals the \u001b[92mtop\u001b[0m japanese animations of recent vintage .\n",
            "\n",
            "in visual fertility treasure planet rivals the \u001b[91muppermost\u001b[0m japanese animations of recent vintage .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 59 / 1 / 13 / 73:  73% 73/100 [00:20<00:07,  3.49it/s]--------------------------------------------- Result 74 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (91%)\u001b[0m\n",
            "\n",
            "enormously \u001b[92menjoyable\u001b[0m , high-adrenaline \u001b[92mdocumentary\u001b[0m .\n",
            "\n",
            "enormously \u001b[91mdroll\u001b[0m , high-adrenaline \u001b[91mpaperwork\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 60 / 1 / 13 / 74:  75% 75/100 [00:21<00:07,  3.54it/s]--------------------------------------------- Result 75 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
            "\n",
            "buy is an \u001b[92maccomplished\u001b[0m actress , and this is a big , \u001b[92mjuicy\u001b[0m role .\n",
            "\n",
            "buy is an \u001b[91mended\u001b[0m actress , and this is a big , \u001b[91mcrusty\u001b[0m role .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 61 / 1 / 13 / 75:  75% 75/100 [00:21<00:07,  3.54it/s]--------------------------------------------- Result 76 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (64%)\u001b[0m\n",
            "\n",
            "it \u001b[92mworks\u001b[0m its magic with such \u001b[92mexuberance\u001b[0m and passion that the film's length becomes a part of its \u001b[92mfun\u001b[0m .\n",
            "\n",
            "it \u001b[91mfunctioned\u001b[0m its magic with such \u001b[91mnaiveté\u001b[0m and passion that the film's length becomes a part of its \u001b[91mbanter\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 62 / 1 / 13 / 76:  76% 76/100 [00:21<00:06,  3.53it/s]--------------------------------------------- Result 77 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
            "\n",
            "\u001b[92mbeautifully\u001b[0m crafted and \u001b[92mbrutally\u001b[0m \u001b[92mhonest\u001b[0m , promises offers an \u001b[92munexpected\u001b[0m \u001b[92mwindow\u001b[0m into the complexities of the middle east \u001b[92mstruggle\u001b[0m and into the \u001b[92mhumanity\u001b[0m of its people .\n",
            "\n",
            "\u001b[91mimpossibly\u001b[0m crafted and \u001b[91mhastily\u001b[0m \u001b[91mfrankly\u001b[0m , promises offers an \u001b[91munforeseen\u001b[0m \u001b[91mbeaker\u001b[0m into the complexities of the middle east \u001b[91mskirmish\u001b[0m and into the \u001b[91mhumans\u001b[0m of its people .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 63 / 1 / 13 / 77:  78% 78/100 [00:22<00:06,  3.51it/s]--------------------------------------------- Result 78 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (81%)\u001b[0m\n",
            "\n",
            "an old-fashioned but emotionally \u001b[92mstirring\u001b[0m adventure tale of the kind they rarely make anymore .\n",
            "\n",
            "an old-fashioned but emotionally \u001b[91mtumult\u001b[0m adventure tale of the kind they rarely make anymore .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 64 / 1 / 13 / 78:  78% 78/100 [00:22<00:06,  3.50it/s]--------------------------------------------- Result 79 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
            "\n",
            "charlotte sometimes is a \u001b[92mgem\u001b[0m . it's always \u001b[92menthralling\u001b[0m .\n",
            "\n",
            "charlotte sometimes is a \u001b[91mbling\u001b[0m . it's always \u001b[91mscintillating\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 65 / 1 / 13 / 79:  79% 79/100 [00:22<00:05,  3.52it/s]--------------------------------------------- Result 80 ---------------------------------------------\n",
            "\u001b[92mPositive (88%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "in my opinion , analyze that is not as funny or entertaining as \u001b[92manalyze\u001b[0m this , but it is a \u001b[92mrespectable\u001b[0m sequel .\n",
            "\n",
            "in my opinion , analyze that is not as funny or entertaining as \u001b[91mdiscusses\u001b[0m this , but it is a \u001b[91mobeyed\u001b[0m sequel .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 66 / 1 / 13 / 80:  81% 81/100 [00:22<00:05,  3.55it/s]--------------------------------------------- Result 81 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
            "\n",
            "a \u001b[92mremarkable\u001b[0m film by bernard rose .\n",
            "\n",
            "a \u001b[91mwhopping\u001b[0m film by bernard rose .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 67 / 1 / 13 / 81:  81% 81/100 [00:22<00:05,  3.55it/s]--------------------------------------------- Result 82 ---------------------------------------------\n",
            "\u001b[92mPositive (81%)\u001b[0m --> \u001b[91mNegative (67%)\u001b[0m\n",
            "\n",
            "zhuangzhuang \u001b[92mcreates\u001b[0m delicate balance of style , text , and subtext that's so simple and precise that anything discordant would topple the balance , but against all odds , nothing does .\n",
            "\n",
            "zhuangzhuang \u001b[91mcrea\u001b[0m delicate balance of style , text , and subtext that's so simple and precise that anything discordant would topple the balance , but against all odds , nothing does .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 68 / 1 / 13 / 82:  82% 82/100 [00:23<00:05,  3.56it/s]--------------------------------------------- Result 83 ---------------------------------------------\n",
            "\u001b[92mPositive (82%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "a much more \u001b[92msuccessful\u001b[0m translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .\n",
            "\n",
            "a much more \u001b[91mavail\u001b[0m translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 69 / 1 / 13 / 83:  84% 84/100 [00:23<00:04,  3.59it/s]--------------------------------------------- Result 84 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
            "\n",
            "an \u001b[92moriginal\u001b[0m and \u001b[92mhighly\u001b[0m cerebral examination of the psychopathic mind\n",
            "\n",
            "an \u001b[91mrudimentary\u001b[0m and \u001b[91mexcessively\u001b[0m cerebral examination of the psychopathic mind\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 70 / 1 / 13 / 84:  84% 84/100 [00:23<00:04,  3.59it/s]--------------------------------------------- Result 85 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (80%)\u001b[0m\n",
            "\n",
            "michel piccoli's \u001b[92mmoving\u001b[0m performance is this films reason for being .\n",
            "\n",
            "michel piccoli's \u001b[91mdisplaced\u001b[0m performance is this films reason for being .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 71 / 1 / 13 / 85:  85% 85/100 [00:23<00:04,  3.62it/s]--------------------------------------------- Result 86 ---------------------------------------------\n",
            "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
            "\n",
            "a \u001b[92mcaptivating\u001b[0m and \u001b[92mintimate\u001b[0m \u001b[92mstudy\u001b[0m about dying and loving . . .\n",
            "\n",
            "a \u001b[91mhallucinatory\u001b[0m and \u001b[91mcosy\u001b[0m \u001b[91mscrutinized\u001b[0m about dying and loving . . .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 72 / 1 / 13 / 86:  87% 87/100 [00:23<00:03,  3.63it/s]--------------------------------------------- Result 87 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
            "\n",
            "this is an \u001b[92melegantly\u001b[0m \u001b[92mbalanced\u001b[0m movie -- every member of the ensemble has something fascinating to do -- that doesn't reveal even a hint of artifice .\n",
            "\n",
            "this is an \u001b[91mprettily\u001b[0m \u001b[91mbalancing\u001b[0m movie -- every member of the ensemble has something fascinating to do -- that doesn't reveal even a hint of artifice .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 73 / 1 / 13 / 87:  87% 87/100 [00:23<00:03,  3.63it/s]--------------------------------------------- Result 88 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "[grant] goes beyond his usual fluttering and stammering and \u001b[92mcaptures\u001b[0m the \u001b[92msoul\u001b[0m of a man in pain who gradually comes to recognize it and deal with it .\n",
            "\n",
            "[grant] goes beyond his usual fluttering and stammering and \u001b[91mincarcerate\u001b[0m the \u001b[91mame\u001b[0m of a man in pain who gradually comes to recognize it and deal with it .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 74 / 1 / 13 / 88:  88% 88/100 [00:24<00:03,  3.63it/s]--------------------------------------------- Result 89 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "a high-spirited buddy movie about the reunion of berlin anarchists who face arrest 15 years after their crime .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 74 / 2 / 13 / 89:  90% 90/100 [00:24<00:02,  3.61it/s]--------------------------------------------- Result 90 ---------------------------------------------\n",
            "\u001b[91mNegative (77%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "about the best thing you could say about narc is that it's a rock-solid little genre picture . whether you like it or not is basically a matter of taste .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 74 / 2 / 14 / 90:  90% 90/100 [00:24<00:02,  3.61it/s]--------------------------------------------- Result 91 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (85%)\u001b[0m\n",
            "\n",
            "an involving , \u001b[92minspirational\u001b[0m \u001b[92mdrama\u001b[0m that sometimes falls prey to its sob-story trappings .\n",
            "\n",
            "an involving , \u001b[91mincite\u001b[0m \u001b[91mcataclysmic\u001b[0m that sometimes falls prey to its sob-story trappings .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 75 / 2 / 14 / 91:  91% 91/100 [00:25<00:02,  3.63it/s]--------------------------------------------- Result 92 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (72%)\u001b[0m\n",
            "\n",
            "some of the most \u001b[92minventive\u001b[0m silliness you are likely to witness in a movie theatre for some time .\n",
            "\n",
            "some of the most \u001b[91mcontrivance\u001b[0m silliness you are likely to witness in a movie theatre for some time .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 76 / 2 / 14 / 92:  93% 93/100 [00:25<00:01,  3.64it/s]--------------------------------------------- Result 93 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "canadian \u001b[92mfilmmaker\u001b[0m gary burns' \u001b[92minventive\u001b[0m and mordantly \u001b[92mhumorous\u001b[0m \u001b[92mtake\u001b[0m on the soullessness of work in the \u001b[92mcity\u001b[0m .\n",
            "\n",
            "canadian \u001b[91mscreenwriter\u001b[0m gary burns' \u001b[91minventor\u001b[0m and mordantly \u001b[91mmockery\u001b[0m \u001b[91mtoma\u001b[0m on the soullessness of work in the \u001b[91mstadt\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 77 / 2 / 14 / 93:  93% 93/100 [00:25<00:01,  3.64it/s]--------------------------------------------- Result 94 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (80%)\u001b[0m\n",
            "\n",
            "a rollicking \u001b[92mride\u001b[0m , with jaw-dropping action sequences , striking villains , a \u001b[92mgorgeous\u001b[0m color palette , astounding technology , \u001b[92mstirring\u001b[0m music and a boffo last hour that leads up to a strangely sinister \u001b[92mhappy\u001b[0m ending .\n",
            "\n",
            "a rollicking \u001b[91mtrips\u001b[0m , with jaw-dropping action sequences , striking villains , a \u001b[91mleggy\u001b[0m color palette , astounding technology , \u001b[91mirate\u001b[0m music and a boffo last hour that leads up to a strangely sinister \u001b[91mhappiest\u001b[0m ending .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 78 / 2 / 14 / 94:  94% 94/100 [00:25<00:01,  3.63it/s]--------------------------------------------- Result 95 ---------------------------------------------\n",
            "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91mNegative (77%)\u001b[0m\n",
            "\n",
            "everyone's insecure in lovely and \u001b[92mamazing\u001b[0m , a \u001b[92mpoignant\u001b[0m and wryly amusing \u001b[92mfilm\u001b[0m about mothers , daughters and their relationships .\n",
            "\n",
            "everyone's insecure in lovely and \u001b[91mwhopping\u001b[0m , a \u001b[91mdisquieting\u001b[0m and wryly amusing \u001b[91mcine\u001b[0m about mothers , daughters and their relationships .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 79 / 2 / 14 / 95:  96% 96/100 [00:26<00:01,  3.66it/s]--------------------------------------------- Result 96 ---------------------------------------------\n",
            "\u001b[92mPositive (63%)\u001b[0m --> \u001b[91mNegative (66%)\u001b[0m\n",
            "\n",
            "the closest thing to the \u001b[92mexperience\u001b[0m of space travel\n",
            "\n",
            "the closest thing to the \u001b[91mpilot\u001b[0m of space travel\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 80 / 2 / 14 / 96:  96% 96/100 [00:26<00:01,  3.66it/s]--------------------------------------------- Result 97 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
            "\n",
            "full of \u001b[92msurprises\u001b[0m .\n",
            "\n",
            "full of \u001b[91mstumped\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 81 / 2 / 14 / 97:  97% 97/100 [00:26<00:00,  3.69it/s]--------------------------------------------- Result 98 ---------------------------------------------\n",
            "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "connoisseurs of chinese film will be \u001b[92mpleased\u001b[0m to discover that tian's meticulous \u001b[92mtalent\u001b[0m \u001b[92mhas\u001b[0m not withered during his enforced hiatus .\n",
            "\n",
            "connoisseurs of chinese film will be \u001b[91mflattered\u001b[0m to discover that tian's meticulous \u001b[91mmanpower\u001b[0m \u001b[91macres\u001b[0m not withered during his enforced hiatus .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 82 / 2 / 14 / 98:  99% 99/100 [00:26<00:00,  3.71it/s]--------------------------------------------- Result 99 ---------------------------------------------\n",
            "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
            "\n",
            "if you can push on through the slow spots , you'll be \u001b[92mrewarded\u001b[0m with some \u001b[92mfine\u001b[0m \u001b[92macting\u001b[0m .\n",
            "\n",
            "if you can push on through the slow spots , you'll be \u001b[91mcompensating\u001b[0m with some \u001b[91mgood\u001b[0m \u001b[91mbehaving\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 83 / 2 / 14 / 99:  99% 99/100 [00:26<00:00,  3.71it/s]--------------------------------------------- Result 100 ---------------------------------------------\n",
            "\u001b[92mPositive (57%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
            "\n",
            "an unusually dry-eyed , even analytical \u001b[92mapproach\u001b[0m to material that is generally played for maximum moisture .\n",
            "\n",
            "an unusually dry-eyed , even analytical \u001b[91mapproaches\u001b[0m to material that is generally played for maximum moisture .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 84 / 2 / 14 / 100: 100% 100/100 [00:26<00:00,  3.73it/s]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 84     |\n",
            "| Number of failed attacks:     | 2      |\n",
            "| Number of skipped attacks:    | 14     |\n",
            "| Original accuracy:            | 86.0%  |\n",
            "| Accuracy under attack:        | 2.0%   |\n",
            "| Attack success rate:          | 97.67% |\n",
            "| Average perturbed word %:     | 13.69% |\n",
            "| Average num. words per input: | 18.45  |\n",
            "| Avg num queries:              | 75.29  |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ],
      "source": [
        "!textattack attack --recipe textfooler --num-examples 100 --model ./outputs/2025-10-12-22-11-09-041877/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyrJM3CaseoL"
      },
      "source": [
        "Looks like our model was 84% successful (makes sense - same evaluation set as `textattack eval`!), meaning that TextAttack attacked the model with 84 examples (since the attack won't run if an example is originally mispredicted). The attack success rate was 98.8%, meaning that TextFooler failed to find an adversarial example only 1.2% (1 out of 84) of the time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xwZqGWz8UVJ"
      },
      "source": [
        "#**TO DO: Robust models**\n",
        "\n",
        "Now that we have trained our model and saw that it was vulnerable to adversarial attacks, your next task is to improve its robustness. We can do so by training a model with adversarial data instead of the normal ones.\n",
        "\n",
        "1. To do so we need to update the training command from above to instruct textattack to use adversarial data generated with textfooler or any other attack during training.\n",
        "\n",
        "To complete the task you can take the help of the documentation of [TextAttack library ](https://textattack.readthedocs.io/en/latest/0_get_started/basic-Intro.html) and command line help option to adversarially train a model on the same dataset.\n",
        "\n",
        "***Hint***: Take a look at the [Trainer class in API](https://textattack.readthedocs.io/en/master/api/trainer.html) user guide and the [Making Vanilla Adversarial Training of NLP Models Feasible!](https://textattack.readthedocs.io/en/master/1start/A2TforVanillaAT.html)\n",
        "\n",
        "2. If the solution you found is expected to take more than 15 minutes to train, look again at the docummentation and adapt your parameters such that it will take between 5-10 minutes due to time restrictions for this class.\n",
        "\n",
        "3. Evaluate if the robustnes of the model has improved by attacking the newly trained model with TextFooler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1FpXmrp5V6g",
        "outputId": "608056af-5669-44f2-b77d-7af6db95252c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 22:16:45.300518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760307405.319837    8788 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760307405.325717    8788 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760307405.342350    8788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307405.342378    8788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307405.342385    8788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307405.342388    8788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "usage: [python -m] textattack <command> [<args>] train [-h]\n",
            "                                                       --model-name-or-path\n",
            "                                                       MODEL_NAME_OR_PATH\n",
            "                                                       [--model-max-length MODEL_MAX_LENGTH]\n",
            "                                                       [--model-num-labels MODEL_NUM_LABELS]\n",
            "                                                       [--attack ATTACK]\n",
            "                                                       [--task-type TASK_TYPE]\n",
            "                                                       --dataset DATASET\n",
            "                                                       [--dataset-train-split DATASET_TRAIN_SPLIT]\n",
            "                                                       [--dataset-eval-split DATASET_EVAL_SPLIT]\n",
            "                                                       [--filter-train-by-labels FILTER_TRAIN_BY_LABELS [FILTER_TRAIN_BY_LABELS ...]]\n",
            "                                                       [--filter-eval-by-labels FILTER_EVAL_BY_LABELS [FILTER_EVAL_BY_LABELS ...]]\n",
            "                                                       [--num-epochs NUM_EPOCHS]\n",
            "                                                       [--num-clean-epochs NUM_CLEAN_EPOCHS]\n",
            "                                                       [--attack-epoch-interval ATTACK_EPOCH_INTERVAL]\n",
            "                                                       [--early-stopping-epochs EARLY_STOPPING_EPOCHS]\n",
            "                                                       [--learning-rate LEARNING_RATE]\n",
            "                                                       [--num-warmup-steps NUM_WARMUP_STEPS]\n",
            "                                                       [--weight-decay WEIGHT_DECAY]\n",
            "                                                       [--per-device-train-batch-size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                                                       [--per-device-eval-batch-size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                                                       [--gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                                       [--random-seed RANDOM_SEED]\n",
            "                                                       [--parallel]\n",
            "                                                       [--load-best-model-at-end]\n",
            "                                                       [--alpha ALPHA]\n",
            "                                                       [--num-train-adv-examples NUM_TRAIN_ADV_EXAMPLES]\n",
            "                                                       [--query-budget-train QUERY_BUDGET_TRAIN]\n",
            "                                                       [--attack-num-workers-per-device ATTACK_NUM_WORKERS_PER_DEVICE]\n",
            "                                                       [--output-dir OUTPUT_DIR]\n",
            "                                                       [--checkpoint-interval-steps CHECKPOINT_INTERVAL_STEPS]\n",
            "                                                       [--checkpoint-interval-epochs CHECKPOINT_INTERVAL_EPOCHS]\n",
            "                                                       [--save-last]\n",
            "                                                       [--log-to-tb]\n",
            "                                                       [--tb-log-dir TB_LOG_DIR]\n",
            "                                                       [--log-to-wandb]\n",
            "                                                       [--wandb-project WANDB_PROJECT]\n",
            "                                                       [--logging-interval-step LOGGING_INTERVAL_STEP]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model-name-or-path MODEL_NAME_OR_PATH, --model MODEL_NAME_OR_PATH\n",
            "                        Name or path of the model we want to create. \"lstm\"\n",
            "                        and \"cnn\" will create TextAttack's LSTM and CNN models\n",
            "                        while any other input will be used to create\n",
            "                        Transformers model. (e.g.\"brt-base-uncased\").\n",
            "                        (default: None)\n",
            "  --model-max-length MODEL_MAX_LENGTH\n",
            "                        The maximum sequence length of the model. (default:\n",
            "                        None)\n",
            "  --model-num-labels MODEL_NUM_LABELS\n",
            "                        The number of labels for classification. (default:\n",
            "                        None)\n",
            "  --attack ATTACK       Attack recipe to use (enables adversarial training)\n",
            "                        (default: None)\n",
            "  --task-type TASK_TYPE\n",
            "                        Type of task model is supposed to perform. Options:\n",
            "                        `classification`, `regression`. (default:\n",
            "                        classification)\n",
            "  --dataset DATASET     dataset for training; will be loaded from `datasets`\n",
            "                        library. if dataset has a subset, separate with a\n",
            "                        colon. ex: `glue^sst2` or `rotten_tomatoes` (default:\n",
            "                        yelp)\n",
            "  --dataset-train-split DATASET_TRAIN_SPLIT\n",
            "                        train dataset split, if non-standard (can\n",
            "                        automatically detect 'train' (default: )\n",
            "  --dataset-eval-split DATASET_EVAL_SPLIT\n",
            "                        val dataset split, if non-standard (can automatically\n",
            "                        detect 'dev', 'validation', 'eval') (default: )\n",
            "  --filter-train-by-labels FILTER_TRAIN_BY_LABELS [FILTER_TRAIN_BY_LABELS ...]\n",
            "                        List of labels to keep in the train dataset and\n",
            "                        discard all others. (default: None)\n",
            "  --filter-eval-by-labels FILTER_EVAL_BY_LABELS [FILTER_EVAL_BY_LABELS ...]\n",
            "                        List of labels to keep in the eval dataset and discard\n",
            "                        all others. (default: None)\n",
            "  --num-epochs NUM_EPOCHS, --epochs NUM_EPOCHS\n",
            "                        Total number of epochs for training. (default: 3)\n",
            "  --num-clean-epochs NUM_CLEAN_EPOCHS\n",
            "                        Number of epochs to train on the clean dataset before\n",
            "                        adversarial training (N/A if --attack unspecified)\n",
            "                        (default: 1)\n",
            "  --attack-epoch-interval ATTACK_EPOCH_INTERVAL\n",
            "                        Generate a new adversarial training set every N\n",
            "                        epochs. (default: 1)\n",
            "  --early-stopping-epochs EARLY_STOPPING_EPOCHS\n",
            "                        Number of epochs validation must increase before\n",
            "                        stopping early (-1 for no early stopping) (default:\n",
            "                        None)\n",
            "  --learning-rate LEARNING_RATE, --lr LEARNING_RATE\n",
            "                        Learning rate for Adam Optimization. (default: 5e-05)\n",
            "  --num-warmup-steps NUM_WARMUP_STEPS\n",
            "                        The number of steps for the warmup phase of linear\n",
            "                        scheduler. (default: 500)\n",
            "  --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay (L2 penalty). (default: 0.01)\n",
            "  --per-device-train-batch-size PER_DEVICE_TRAIN_BATCH_SIZE\n",
            "                        The batch size per GPU/CPU for training. (default: 8)\n",
            "  --per-device-eval-batch-size PER_DEVICE_EVAL_BATCH_SIZE\n",
            "                        The batch size per GPU/CPU for evaluation. (default:\n",
            "                        32)\n",
            "  --gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS\n",
            "                        Number of updates steps to accumulate the gradients\n",
            "                        for, before performing a backward/update pass.\n",
            "                        (default: 1)\n",
            "  --random-seed RANDOM_SEED\n",
            "                        Random seed. (default: 786)\n",
            "  --parallel            If set, run training on multiple GPUs. (default:\n",
            "                        False)\n",
            "  --load-best-model-at-end\n",
            "                        If set, keep track of the best model across training\n",
            "                        and load it at the end. (default: False)\n",
            "  --alpha ALPHA         The weight of adversarial loss. (default: 1.0)\n",
            "  --num-train-adv-examples NUM_TRAIN_ADV_EXAMPLES\n",
            "                        The number of samples to attack when generating\n",
            "                        adversarial training set. Default is -1 (which is all\n",
            "                        possible samples). (default: -1)\n",
            "  --query-budget-train QUERY_BUDGET_TRAIN\n",
            "                        The max query budget to use when generating\n",
            "                        adversarial training set. (default: None)\n",
            "  --attack-num-workers-per-device ATTACK_NUM_WORKERS_PER_DEVICE\n",
            "                        Number of worker processes to run per device for\n",
            "                        attack. Same as `num_workers_per_device` argument for\n",
            "                        `AttackArgs`. (default: 1)\n",
            "  --output-dir OUTPUT_DIR\n",
            "                        Directory to output training logs and checkpoints.\n",
            "                        (default: ./outputs/2025-10-12-22-16-51-523711)\n",
            "  --checkpoint-interval-steps CHECKPOINT_INTERVAL_STEPS\n",
            "                        Save model checkpoint after every N updates to the\n",
            "                        model. (default: None)\n",
            "  --checkpoint-interval-epochs CHECKPOINT_INTERVAL_EPOCHS\n",
            "                        Save model checkpoint after every N epochs. (default:\n",
            "                        None)\n",
            "  --save-last           If set, save the model at end of training. Can be used\n",
            "                        with `--load-best-model-at-end` to save the best model\n",
            "                        at the end. (default: True)\n",
            "  --log-to-tb           If set, log to Tensorboard (default: False)\n",
            "  --tb-log-dir TB_LOG_DIR\n",
            "                        Path of Tensorboard log directory. (default: None)\n",
            "  --log-to-wandb        If set, log to Wandb. (default: False)\n",
            "  --wandb-project WANDB_PROJECT\n",
            "                        Name of Wandb project for logging. (default:\n",
            "                        textattack)\n",
            "  --logging-interval-step LOGGING_INTERVAL_STEP\n",
            "                        Log to Tensorboard/Wandb every N steps. (default: 1)\n"
          ]
        }
      ],
      "source": [
        "!textattack train --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Esv_tDXpVIr"
      },
      "source": [
        "## Training with adversarial data\n",
        "\n",
        "--num-epochs 2 : Train for 2 epochs in total.\n",
        "\n",
        "--num-clean-epochs 0 : Do zero epochs on clean data. From step 1, we're doing adversarial training only, to make it faster, even if it reduces little bit clean accuracy.\n",
        "\n",
        "\n",
        "--attack textfooler : TextFooler word attack to generate training adversarial data. It replaces words with semantically similar substitutes under constraints.\n",
        "\n",
        "--num-train-adv-examples 3000 : Generate 3000 adversarial training examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO-KoPavaamJ",
        "outputId": "ea5cb169-a040-4b62-bbd2-dc125f00201d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 22:20:41.317431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760307641.337108    9823 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760307641.343126    9823 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760307641.358315    9823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307641.358339    9823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307641.358343    9823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760307641.358348    9823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "\u001b[34;1mtextattack\u001b[0m: Writing logs to ./outputs/2025-10-12-22-20-48-558446/train_log.txt.\n",
            "\u001b[34;1mtextattack\u001b[0m: Wrote original training args to ./outputs/2025-10-12-22-20-48-558446/training_args.json.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n",
            "\u001b[34;1mtextattack\u001b[0m:   Num examples = 8530\n",
            "\u001b[34;1mtextattack\u001b[0m:   Num epochs = 2\n",
            "\u001b[34;1mtextattack\u001b[0m:   Num clean epochs = 0\n",
            "\u001b[34;1mtextattack\u001b[0m:   Instantaneous batch size per device = 128\n",
            "\u001b[34;1mtextattack\u001b[0m:   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "\u001b[34;1mtextattack\u001b[0m:   Gradient accumulation steps = 1\n",
            "\u001b[34;1mtextattack\u001b[0m:   Total optimization steps = 182\n",
            "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
            "\u001b[34;1mtextattack\u001b[0m: Epoch 1\n",
            "\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n",
            "  0% 0/3000 [00:00<?, ?it/s]2025-10-12 22:21:18.403077: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1760307678.407053    9823 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13600 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2025-10-12 22:21:19.192887: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-10-12 22:21:19.225917: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-10-12 22:21:19.258848: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-10-12 22:21:19.292602: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-10-12 22:21:19.326968: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "[Succeeded / Failed / Skipped / Total] 3000 / 176 / 3016 / 6192: 100% 3000/3000 [15:40<00:00,  3.19it/s]\n",
            "\n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Total number of attack results: 6192\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack success rate: 94.46% [3000 / 3176]\n",
            "Loss 0.64989: 100% 91/91 [00:55<00:00,  1.63it/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 59.86%\n",
            "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 79.83%\n",
            "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2025-10-12-22-20-48-558446/best_model/\n",
            "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
            "\u001b[34;1mtextattack\u001b[0m: Epoch 2\n",
            "\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n",
            "[Succeeded / Failed / Skipped / Total] 3000 / 197 / 751 / 3948: 100% 3000/3000 [13:33<00:00,  3.69it/s]\n",
            "\n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Total number of attack results: 3948\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack success rate: 93.84% [3000 / 3197]\n",
            "Loss 0.56627: 100% 91/91 [00:55<00:00,  1.64it/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 76.01%\n",
            "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 81.71%\n",
            "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2025-10-12-22-20-48-558446/best_model/\n",
            "\u001b[34;1mtextattack\u001b[0m: Wrote README to ./outputs/2025-10-12-22-20-48-558446/README.md.\n"
          ]
        }
      ],
      "source": [
        "!textattack train --model-name-or-path distilbert-base-uncased --dataset rotten_tomatoes --model-num-labels 2 --model-max-length 64 --per-device-train-batch-size 128 --num-epochs 2 --num-clean-epochs 0 --attack textfooler --num-train-adv-examples 3000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmqop9-trZEy"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4s6OVO_oT7q",
        "outputId": "c8a256dd-264a-4b62-9055-ccf23c29c78f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 22:56:24.930221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760309784.949586   19045 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760309784.955506   19045 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760309784.970105   19045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760309784.970130   19045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760309784.970134   19045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760309784.970137   19045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Got 1000 predictions.\n",
            "\u001b[34;1mtextattack\u001b[0m: Correct 825/1000 (\u001b[94m82.50%\u001b[0m)\n"
          ]
        }
      ],
      "source": [
        "!textattack eval --num-examples 1000 --model ./outputs/2025-10-12-22-20-48-558446/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGJO-DrjrlP_"
      },
      "source": [
        "We were able to train a model up to 82.5% accuracy on the test dataset, and this even if we did zero epochs on clean data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk-hZgLVxJ00",
        "outputId": "4ee5865e-7ead-481a-9bef-9c068dba75e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-12 22:58:01.997376: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760309882.028939   19469 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760309882.038600   19469 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760309882.061979   19469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760309882.062014   19469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760309882.062023   19469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760309882.062029   19469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]2025-10-12 22:58:18.734351: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1760309898.734500   19469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13576 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "  1% 1/100 [00:10<17:13, 10.44s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (53%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
            "\n",
            "lovingly photographed in the manner of a golden book sprung to life , stuart little 2 \u001b[92mmanages\u001b[0m sweetness largely without stickiness .\n",
            "\n",
            "lovingly photographed in the manner of a golden book sprung to life , stuart little 2 \u001b[91mmanage\u001b[0m sweetness largely without stickiness .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   2% 2/100 [00:10<08:53,  5.44s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (75%)\u001b[0m\n",
            "\n",
            "\u001b[92mconsistently\u001b[0m \u001b[92mclever\u001b[0m and \u001b[92msuspenseful\u001b[0m .\n",
            "\n",
            "\u001b[91mceaselessly\u001b[0m \u001b[91mmalin\u001b[0m and \u001b[91mmelodramatic\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:   2% 2/100 [00:10<08:53,  5.44s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[91mNegative (83%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 1 / 3:   4% 4/100 [00:11<04:41,  2.93s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
            "\n",
            "the story \u001b[92mgives\u001b[0m \u001b[92mample\u001b[0m \u001b[92mopportunity\u001b[0m for large-scale \u001b[92maction\u001b[0m and \u001b[92msuspense\u001b[0m , which \u001b[92mdirector\u001b[0m \u001b[92mshekhar\u001b[0m kapur \u001b[92msupplies\u001b[0m with \u001b[92mtremendous\u001b[0m \u001b[92mskill\u001b[0m .\n",
            "\n",
            "the story \u001b[91mposes\u001b[0m \u001b[91mextensive\u001b[0m \u001b[91mrisk\u001b[0m for large-scale \u001b[91mwork\u001b[0m and \u001b[91mwaited\u001b[0m , which \u001b[91mmanagement\u001b[0m \u001b[91mprasad\u001b[0m kapur \u001b[91mmerchandise\u001b[0m with \u001b[91msizable\u001b[0m \u001b[91mjurisdictional\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 1 / 4:   4% 4/100 [00:11<04:41,  2.93s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (73%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "red dragon \" never cuts corners .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   6% 6/100 [00:11<03:07,  1.99s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mPositive (87%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "fresnadillo \u001b[92mhas\u001b[0m something serious to say about the \u001b[92mways\u001b[0m in which extravagant chance can distort our perspective and throw us off the \u001b[92mpath\u001b[0m of good sense .\n",
            "\n",
            "fresnadillo \u001b[91mai\u001b[0m something serious to say about the \u001b[91mpleas\u001b[0m in which extravagant chance can distort our perspective and throw us off the \u001b[91mcourse\u001b[0m of good sense .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 2 / 6:   6% 6/100 [00:11<03:07,  1.99s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (71%)\u001b[0m\n",
            "\n",
            "throws in enough \u001b[92mclever\u001b[0m and \u001b[92munexpected\u001b[0m \u001b[92mtwists\u001b[0m to make the formula feel fresh .\n",
            "\n",
            "throws in enough \u001b[91mtermite\u001b[0m and \u001b[91munwanted\u001b[0m \u001b[91mtendrils\u001b[0m to make the formula feel fresh .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 2 / 7:   8% 8/100 [00:12<02:20,  1.52s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91mNegative (62%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "weighty and ponderous but every bit as filling as the treat of the title .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 3 / 8:   8% 8/100 [00:12<02:20,  1.52s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "a \u001b[92mreal\u001b[0m audience-pleaser that \u001b[92mwill\u001b[0m \u001b[92mstrike\u001b[0m a \u001b[92mchord\u001b[0m with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
            "\n",
            "a \u001b[91mactual\u001b[0m audience-pleaser that \u001b[91mgoing\u001b[0m \u001b[91mattacked\u001b[0m a \u001b[91mchords\u001b[0m with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 3 / 9:  10% 10/100 [00:12<01:55,  1.28s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (78%)\u001b[0m\n",
            "\n",
            "generates an \u001b[92menormous\u001b[0m \u001b[92mfeeling\u001b[0m of \u001b[92mempathy\u001b[0m for its \u001b[92mcharacters\u001b[0m .\n",
            "\n",
            "generates an \u001b[91mdreaded\u001b[0m \u001b[91mprinting\u001b[0m of \u001b[91mpity\u001b[0m for its \u001b[91mspecification\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 3 / 10:  10% 10/100 [00:12<01:55,  1.28s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (59%)\u001b[0m\n",
            "\n",
            "exposing the \u001b[92mways\u001b[0m we fool ourselves is one hour photo's real \u001b[92mstrength\u001b[0m .\n",
            "\n",
            "exposing the \u001b[91mmode\u001b[0m we fool ourselves is one hour photo's real \u001b[91mkraft\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 3 / 11:  12% 12/100 [00:13<01:36,  1.10s/it]--------------------------------------------- Result 12 ---------------------------------------------\n",
            "\u001b[92mPositive (60%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful \u001b[92mview\u001b[0m of american life .\n",
            "\n",
            "it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful \u001b[91mvisualise\u001b[0m of american life .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 3 / 12:  12% 12/100 [00:13<01:36,  1.10s/it]--------------------------------------------- Result 13 ---------------------------------------------\n",
            "\u001b[92mPositive (81%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "mostly , [goldbacher] just \u001b[92mlets\u001b[0m her complicated characters be unruly , confusing and , through it all , human .\n",
            "\n",
            "mostly , [goldbacher] just \u001b[91mletting\u001b[0m her complicated characters be unruly , confusing and , through it all , human .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 3 / 13:  14% 14/100 [00:13<01:22,  1.04it/s]--------------------------------------------- Result 14 ---------------------------------------------\n",
            "\u001b[92mPositive (88%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            ". . . quite \u001b[92mgood\u001b[0m at \u001b[92mproviding\u001b[0m some \u001b[92mgood\u001b[0m old fashioned spooks .\n",
            "\n",
            ". . . quite \u001b[91mbest\u001b[0m at \u001b[91mquotation\u001b[0m some \u001b[91mallright\u001b[0m old fashioned spooks .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 3 / 14:  14% 14/100 [00:13<01:22,  1.04it/s]--------------------------------------------- Result 15 ---------------------------------------------\n",
            "\u001b[91mNegative (93%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "at its worst , the movie is pretty diverting ; the pity is that it rarely achieves its best .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 4 / 15:  16% 16/100 [00:13<01:13,  1.15it/s]--------------------------------------------- Result 16 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (87%)\u001b[0m\n",
            "\n",
            "scherfig's light-hearted \u001b[92mprofile\u001b[0m of \u001b[92memotional\u001b[0m \u001b[92mdesperation\u001b[0m is achingly \u001b[92mhonest\u001b[0m and \u001b[92mdelightfully\u001b[0m \u001b[92mcheeky\u001b[0m .\n",
            "\n",
            "scherfig's light-hearted \u001b[91mimage\u001b[0m of \u001b[91mcorny\u001b[0m \u001b[91mdesperate\u001b[0m is achingly \u001b[91mfranco\u001b[0m and \u001b[91mneatly\u001b[0m \u001b[91mshameless\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 12 / 0 / 4 / 16:  16% 16/100 [00:13<01:13,  1.15it/s]--------------------------------------------- Result 17 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "a \u001b[92mjourney\u001b[0m \u001b[92mspanning\u001b[0m nearly three decades of bittersweet camaraderie and history , in which we \u001b[92mfeel\u001b[0m that we truly know what makes holly and marina tick , and our \u001b[92mhearts\u001b[0m \u001b[92mgo\u001b[0m out to them as both \u001b[92mcontinue\u001b[0m to negotiate their imperfect , love-hate \u001b[92mrelationship\u001b[0m .\n",
            "\n",
            "a \u001b[91mcircuits\u001b[0m \u001b[91mprolonging\u001b[0m nearly three decades of bittersweet camaraderie and history , in which we \u001b[91mguess\u001b[0m that we truly know what makes holly and marina tick , and our \u001b[91mcardiology\u001b[0m \u001b[91mdisappear\u001b[0m out to them as both \u001b[91mceaseless\u001b[0m to negotiate their imperfect , love-hate \u001b[91mlier\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 13 / 0 / 4 / 17:  18% 18/100 [00:15<01:09,  1.18it/s]--------------------------------------------- Result 18 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "the \u001b[92mwonderfully\u001b[0m \u001b[92mlush\u001b[0m morvern callar is \u001b[92mpure\u001b[0m punk \u001b[92mexistentialism\u001b[0m , and \u001b[92mms\u001b[0m . ramsay and her co-writer , \u001b[92mliana\u001b[0m dognini , have dramatized the alan warner novel , which itself felt like an \u001b[92manswer\u001b[0m to irvine welsh's book trainspotting .\n",
            "\n",
            "the \u001b[91moddly\u001b[0m \u001b[91mplush\u001b[0m morvern callar is \u001b[91mmere\u001b[0m punk \u001b[91mmaterialism\u001b[0m , and \u001b[91mmadam\u001b[0m . ramsay and her co-writer , \u001b[91mcamilla\u001b[0m dognini , have dramatized the alan warner novel , which itself felt like an \u001b[91mreacts\u001b[0m to irvine welsh's book trainspotting .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 14 / 0 / 4 / 18:  18% 18/100 [00:15<01:09,  1.18it/s]--------------------------------------------- Result 19 ---------------------------------------------\n",
            "\u001b[92mPositive (62%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "as it \u001b[92mturns\u001b[0m out , you can go \u001b[92mhome\u001b[0m again .\n",
            "\n",
            "as it \u001b[91mswivel\u001b[0m out , you can go \u001b[91mhouse\u001b[0m again .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 15 / 0 / 4 / 19:  20% 20/100 [00:15<01:01,  1.29it/s]--------------------------------------------- Result 20 ---------------------------------------------\n",
            "\u001b[92mPositive (89%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "you've already seen city by the sea under a variety of titles , but it's \u001b[92mworth\u001b[0m yet another visit .\n",
            "\n",
            "you've already seen city by the sea under a variety of titles , but it's \u001b[91mchastisement\u001b[0m yet another visit .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 16 / 0 / 4 / 20:  20% 20/100 [00:15<01:01,  1.29it/s]--------------------------------------------- Result 21 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "this kind of hands-on \u001b[92mstorytelling\u001b[0m is ultimately what \u001b[92mmakes\u001b[0m shanghai ghetto move beyond a \u001b[92mgood\u001b[0m , dry , reliable textbook and what \u001b[92mallows\u001b[0m it to rank with its \u001b[92mworthy\u001b[0m \u001b[92mpredecessors\u001b[0m .\n",
            "\n",
            "this kind of hands-on \u001b[91mmyth\u001b[0m is ultimately what \u001b[91mfact\u001b[0m shanghai ghetto move beyond a \u001b[91msuitable\u001b[0m , dry , reliable textbook and what \u001b[91mauthorizing\u001b[0m it to rank with its \u001b[91mlegitimate\u001b[0m \u001b[91mparentage\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 17 / 0 / 4 / 21:  22% 22/100 [00:16<00:58,  1.34it/s]--------------------------------------------- Result 22 ---------------------------------------------\n",
            "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "making such a tragedy the backdrop to a love story risks trivializing it , though chouraqui no \u001b[92mdoubt\u001b[0m intended the \u001b[92mfilm\u001b[0m to affirm love's \u001b[92mpower\u001b[0m to \u001b[92mhelp\u001b[0m people endure almost unimaginable horror .\n",
            "\n",
            "making such a tragedy the backdrop to a love story risks trivializing it , though chouraqui no \u001b[91mhint\u001b[0m intended the \u001b[91mtheatres\u001b[0m to affirm love's \u001b[91mjurisdiction\u001b[0m to \u001b[91msuccor\u001b[0m people endure almost unimaginable horror .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 18 / 0 / 4 / 22:  22% 22/100 [00:16<00:58,  1.34it/s]--------------------------------------------- Result 23 ---------------------------------------------\n",
            "\u001b[92mPositive (79%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "grown-up quibbles are beside the point here . the little \u001b[92mgirls\u001b[0m \u001b[92munderstand\u001b[0m , and mccracken \u001b[92mknows\u001b[0m that's all that matters .\n",
            "\n",
            "grown-up quibbles are beside the point here . the little \u001b[91mbabes\u001b[0m \u001b[91mincluding\u001b[0m , and mccracken \u001b[91mknowing\u001b[0m that's all that matters .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 19 / 0 / 4 / 23:  24% 24/100 [00:17<00:53,  1.41it/s]--------------------------------------------- Result 24 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (64%)\u001b[0m\n",
            "\n",
            "a \u001b[92mpowerful\u001b[0m , \u001b[92mchilling\u001b[0m , and affecting \u001b[92mstudy\u001b[0m of one man's \u001b[92mdying\u001b[0m \u001b[92mfall\u001b[0m .\n",
            "\n",
            "a \u001b[91msolids\u001b[0m , \u001b[91mcolder\u001b[0m , and affecting \u001b[91mresearch\u001b[0m of one man's \u001b[91mkillings\u001b[0m \u001b[91mdecreased\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 20 / 0 / 4 / 24:  24% 24/100 [00:17<00:53,  1.41it/s]--------------------------------------------- Result 25 ---------------------------------------------\n",
            "\u001b[91mNegative (91%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "this is a fascinating film because there is no clear-cut hero and no all-out villain .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 20 / 0 / 5 / 25:  26% 26/100 [00:17<00:48,  1.52it/s]--------------------------------------------- Result 26 ---------------------------------------------\n",
            "\u001b[92mPositive (84%)\u001b[0m --> \u001b[91mNegative (64%)\u001b[0m\n",
            "\n",
            "a dreadful day in irish history is given \u001b[92mpassionate\u001b[0m , if somewhat flawed , treatment .\n",
            "\n",
            "a dreadful day in irish history is given \u001b[91mgreedy\u001b[0m , if somewhat flawed , treatment .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 21 / 0 / 5 / 26:  26% 26/100 [00:17<00:48,  1.52it/s]--------------------------------------------- Result 27 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (72%)\u001b[0m\n",
            "\n",
            ". . . a \u001b[92mgood\u001b[0m film that must have baffled the folks in the marketing department .\n",
            "\n",
            ". . . a \u001b[91mok\u001b[0m film that must have baffled the folks in the marketing department .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 22 / 0 / 5 / 27:  28% 28/100 [00:17<00:45,  1.57it/s]--------------------------------------------- Result 28 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            ". . . is \u001b[92mfunny\u001b[0m in the \u001b[92mway\u001b[0m that \u001b[92mmakes\u001b[0m you ache with \u001b[92msadness\u001b[0m ( the \u001b[92mway\u001b[0m chekhov is funny ) , \u001b[92mprofound\u001b[0m without ever being self-important , \u001b[92mwarm\u001b[0m without ever \u001b[92msuccumbing\u001b[0m to \u001b[92msentimentality\u001b[0m .\n",
            "\n",
            ". . . is \u001b[91mjest\u001b[0m in the \u001b[91mlanes\u001b[0m that \u001b[91mdoes\u001b[0m you ache with \u001b[91mangst\u001b[0m ( the \u001b[91mrouting\u001b[0m chekhov is funny ) , \u001b[91mshum\u001b[0m without ever being self-important , \u001b[91mheats\u001b[0m without ever \u001b[91mfending\u001b[0m to \u001b[91mbunch\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 0 / 5 / 28:  28% 28/100 [00:17<00:45,  1.57it/s]--------------------------------------------- Result 29 ---------------------------------------------\n",
            "\u001b[91mNegative (93%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "devotees of star trek ii : the wrath of khan will feel a nagging sense of deja vu , and the grandeur of the best next generation episodes is lacking .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 0 / 6 / 29:  30% 30/100 [00:18<00:43,  1.61it/s]--------------------------------------------- Result 30 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "a soul-stirring documentary about the israeli/palestinian conflict as revealed through the eyes of some children who remain curious about each other against all odds .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 1 / 6 / 30:  30% 30/100 [00:18<00:43,  1.61it/s]--------------------------------------------- Result 31 ---------------------------------------------\n",
            "\u001b[91mNegative (68%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "what's so striking about jolie's performance is that she never lets her character become a caricature -- not even with that radioactive hair .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 1 / 7 / 31:  31% 31/100 [00:18<00:41,  1.67it/s]--------------------------------------------- Result 32 ---------------------------------------------\n",
            "\u001b[91mNegative (82%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "the main story . . . is compelling enough , but it's difficult to shrug off the annoyance of that chatty fish .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 23 / 1 / 8 / 32:  32% 32/100 [00:18<00:39,  1.72it/s]--------------------------------------------- Result 33 ---------------------------------------------\n",
            "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (68%)\u001b[0m\n",
            "\n",
            "the performances are \u001b[92mimmaculate\u001b[0m , with roussillon providing comic relief .\n",
            "\n",
            "the performances are \u001b[91mspotless\u001b[0m , with roussillon providing comic relief .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 24 / 1 / 8 / 33:  34% 34/100 [00:19<00:38,  1.74it/s]--------------------------------------------- Result 34 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "kinnear . . . \u001b[92mgives\u001b[0m his \u001b[92mbest\u001b[0m \u001b[92mscreen\u001b[0m \u001b[92mperformance\u001b[0m with an \u001b[92moddly\u001b[0m \u001b[92mwinning\u001b[0m \u001b[92mportrayal\u001b[0m of one of life's \u001b[92multimate\u001b[0m \u001b[92mlosers\u001b[0m .\n",
            "\n",
            "kinnear . . . \u001b[91msupplying\u001b[0m his \u001b[91mgood\u001b[0m \u001b[91mvisor\u001b[0m \u001b[91mrealization\u001b[0m with an \u001b[91mannoyingly\u001b[0m \u001b[91mwins\u001b[0m \u001b[91mspitting\u001b[0m of one of life's \u001b[91mfinale\u001b[0m \u001b[91mfuckers\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 25 / 1 / 8 / 34:  34% 34/100 [00:19<00:38,  1.74it/s]--------------------------------------------- Result 35 ---------------------------------------------\n",
            "\u001b[91mNegative (63%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "hugh grant , who has a good line in charm , has never been more charming than in about a boy .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 25 / 1 / 9 / 35:  35% 35/100 [00:19<00:36,  1.79it/s]--------------------------------------------- Result 36 ---------------------------------------------\n",
            "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (66%)\u001b[0m\n",
            "\n",
            "there's a lot of tooth in roger dodger . but what's \u001b[92mnice\u001b[0m is that there's a casual intelligence that \u001b[92mpermeates\u001b[0m the script .\n",
            "\n",
            "there's a lot of tooth in roger dodger . but what's \u001b[91mgentil\u001b[0m is that there's a casual intelligence that \u001b[91mobscures\u001b[0m the script .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 26 / 1 / 9 / 36:  36% 36/100 [00:19<00:35,  1.81it/s]--------------------------------------------- Result 37 ---------------------------------------------\n",
            "\u001b[91mNegative (58%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "reminiscent of alfred hitchcock's thrillers , most of the scary parts in 'signs' occur while waiting for things to happen .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 26 / 1 / 10 / 37:  38% 38/100 [00:20<00:33,  1.87it/s]--------------------------------------------- Result 38 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (68%)\u001b[0m\n",
            "\n",
            "one of the \u001b[92mbest\u001b[0m looking and \u001b[92mstylish\u001b[0m \u001b[92manimated\u001b[0m \u001b[92mmovies\u001b[0m in \u001b[92mquite\u001b[0m a while . . .\n",
            "\n",
            "one of the \u001b[91mupper\u001b[0m looking and \u001b[91mfashionable\u001b[0m \u001b[91mprompted\u001b[0m \u001b[91mflick\u001b[0m in \u001b[91mtoo\u001b[0m a while . . .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 27 / 1 / 10 / 38:  38% 38/100 [00:20<00:33,  1.87it/s]--------------------------------------------- Result 39 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (58%)\u001b[0m\n",
            "\n",
            "its use of the \u001b[92mthriller\u001b[0m form to examine the labyrinthine \u001b[92mways\u001b[0m in which people's \u001b[92mlives\u001b[0m cross and change , \u001b[92mbuffeted\u001b[0m by \u001b[92mevents\u001b[0m seemingly out of their control , is \u001b[92mintriguing\u001b[0m , provocative \u001b[92mstuff\u001b[0m .\n",
            "\n",
            "its use of the \u001b[91mthrillers\u001b[0m form to examine the labyrinthine \u001b[91mprocedures\u001b[0m in which people's \u001b[91mcapita\u001b[0m cross and change , \u001b[91maghast\u001b[0m by \u001b[91mdemonstration\u001b[0m seemingly out of their control , is \u001b[91mpuzzling\u001b[0m , provocative \u001b[91manything\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 28 / 1 / 10 / 39:  39% 39/100 [00:21<00:33,  1.85it/s]--------------------------------------------- Result 40 ---------------------------------------------\n",
            "\u001b[92mPositive (80%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "denver \u001b[92mshould\u001b[0m not get the first and last look at one of the most triumphant performances of vanessa redgrave's career . it deserves to be seen everywhere .\n",
            "\n",
            "denver \u001b[91mneeded\u001b[0m not get the first and last look at one of the most triumphant performances of vanessa redgrave's career . it deserves to be seen everywhere .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 29 / 1 / 10 / 40:  40% 40/100 [00:21<00:31,  1.88it/s]--------------------------------------------- Result 41 ---------------------------------------------\n",
            "\u001b[92mPositive (51%)\u001b[0m --> \u001b[91mNegative (70%)\u001b[0m\n",
            "\n",
            "you needn't be steeped in '50s sociology , pop culture or movie lore to appreciate the emotional depth of haynes' work . \u001b[92mthough\u001b[0m haynes' style apes films from the period . . . its message is not rooted in that decade .\n",
            "\n",
            "you needn't be steeped in '50s sociology , pop culture or movie lore to appreciate the emotional depth of haynes' work . \u001b[91malbeit\u001b[0m haynes' style apes films from the period . . . its message is not rooted in that decade .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 30 / 1 / 10 / 41:  42% 42/100 [00:21<00:29,  1.94it/s]--------------------------------------------- Result 42 ---------------------------------------------\n",
            "\u001b[92mPositive (88%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "waiting for \u001b[92mgodard\u001b[0m can \u001b[92mbe\u001b[0m \u001b[92mfruitful\u001b[0m : 'in \u001b[92mpraise\u001b[0m of love' is the director's epitaph for himself .\n",
            "\n",
            "waiting for \u001b[91mhitchcock\u001b[0m can \u001b[91meither\u001b[0m \u001b[91mlucrative\u001b[0m : 'in \u001b[91mpraising\u001b[0m of love' is the director's epitaph for himself .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 31 / 1 / 10 / 42:  42% 42/100 [00:21<00:29,  1.94it/s]--------------------------------------------- Result 43 ---------------------------------------------\n",
            "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (78%)\u001b[0m\n",
            "\n",
            "a gangster movie with the \u001b[92mcapacity\u001b[0m to \u001b[92msurprise\u001b[0m .\n",
            "\n",
            "a gangster movie with the \u001b[91mjurisdictional\u001b[0m to \u001b[91mdumbfounded\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 32 / 1 / 10 / 43:  43% 43/100 [00:21<00:28,  1.97it/s]--------------------------------------------- Result 44 ---------------------------------------------\n",
            "\u001b[92mPositive (82%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are \u001b[92mworth\u001b[0m the price of admission . . . if \" gory mayhem \" is your idea of a good time .\n",
            "\n",
            "the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are \u001b[91mpriceless\u001b[0m the price of admission . . . if \" gory mayhem \" is your idea of a good time .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 33 / 1 / 10 / 44:  44% 44/100 [00:21<00:27,  2.01it/s]--------------------------------------------- Result 45 ---------------------------------------------\n",
            "\u001b[92mPositive (50%)\u001b[0m --> \u001b[91mNegative (75%)\u001b[0m\n",
            "\n",
            "if not a home run , then at least a \u001b[92msolid\u001b[0m base hit .\n",
            "\n",
            "if not a home run , then at least a \u001b[91msonar\u001b[0m base hit .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 34 / 1 / 10 / 45:  46% 46/100 [00:22<00:25,  2.08it/s]--------------------------------------------- Result 46 ---------------------------------------------\n",
            "\u001b[92mPositive (79%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
            "\n",
            "goldmember is \u001b[92mfunny\u001b[0m enough to justify the embarrassment of bringing a barf bag to the moviehouse .\n",
            "\n",
            "goldmember is \u001b[91mcomical\u001b[0m enough to justify the embarrassment of bringing a barf bag to the moviehouse .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 35 / 1 / 10 / 46:  46% 46/100 [00:22<00:25,  2.08it/s]--------------------------------------------- Result 47 ---------------------------------------------\n",
            "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            ". . . a fairly disposable yet still \u001b[92mentertaining\u001b[0m b \u001b[92mpicture\u001b[0m .\n",
            "\n",
            ". . . a fairly disposable yet still \u001b[91mchuckles\u001b[0m b \u001b[91mpictured\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 36 / 1 / 10 / 47:  47% 47/100 [00:22<00:25,  2.10it/s]--------------------------------------------- Result 48 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "it may not be particularly \u001b[92minnovative\u001b[0m , but the film's \u001b[92mcrisp\u001b[0m , unaffected \u001b[92mstyle\u001b[0m and air of \u001b[92mgentle\u001b[0m \u001b[92mlonging\u001b[0m \u001b[92mmake\u001b[0m it unexpectedly \u001b[92mrewarding\u001b[0m .\n",
            "\n",
            "it may not be particularly \u001b[91munpublished\u001b[0m , but the film's \u001b[91mabrupt\u001b[0m , unaffected \u001b[91mstyling\u001b[0m and air of \u001b[91msaggy\u001b[0m \u001b[91mvacuuming\u001b[0m \u001b[91mget\u001b[0m it unexpectedly \u001b[91mcompensation\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 37 / 1 / 10 / 48:  48% 48/100 [00:22<00:24,  2.10it/s]--------------------------------------------- Result 49 ---------------------------------------------\n",
            "\u001b[92mPositive (84%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "the film \u001b[92mtruly\u001b[0m does rescue [the funk brothers] from motown's shadows . it's about time .\n",
            "\n",
            "the film \u001b[91mexactly\u001b[0m does rescue [the funk brothers] from motown's shadows . it's about time .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 38 / 1 / 10 / 49:  50% 50/100 [00:23<00:23,  2.12it/s]--------------------------------------------- Result 50 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "drawing on an \u001b[92mirresistible\u001b[0m , \u001b[92mlanguid\u001b[0m romanticism , byler \u001b[92mreveals\u001b[0m the \u001b[92mways\u001b[0m in which a sultry evening or a beer-fueled afternoon in the \u001b[92msun\u001b[0m can \u001b[92minspire\u001b[0m even the most retiring \u001b[92mheart\u001b[0m to venture forth .\n",
            "\n",
            "drawing on an \u001b[91minevitable\u001b[0m , \u001b[91mdowncast\u001b[0m romanticism , byler \u001b[91mbetrays\u001b[0m the \u001b[91mmenu\u001b[0m in which a sultry evening or a beer-fueled afternoon in the \u001b[91msunny\u001b[0m can \u001b[91mpromoting\u001b[0m even the most retiring \u001b[91mcoeur\u001b[0m to venture forth .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 39 / 1 / 10 / 50:  50% 50/100 [00:23<00:23,  2.12it/s]--------------------------------------------- Result 51 ---------------------------------------------\n",
            "\u001b[91mNegative (87%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 39 / 1 / 11 / 51:  51% 51/100 [00:23<00:22,  2.16it/s]--------------------------------------------- Result 52 ---------------------------------------------\n",
            "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "[scherfig] \u001b[92mhas\u001b[0m made a \u001b[92mmovie\u001b[0m that will \u001b[92mleave\u001b[0m you wondering about the characters' \u001b[92mlives\u001b[0m after the \u001b[92mclever\u001b[0m credits \u001b[92mroll\u001b[0m .\n",
            "\n",
            "[scherfig] \u001b[91mgot\u001b[0m made a \u001b[91mcine\u001b[0m that will \u001b[91mleft\u001b[0m you wondering about the characters' \u001b[91mllfe\u001b[0m after the \u001b[91msmarter\u001b[0m credits \u001b[91mstabilizer\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 40 / 1 / 11 / 52:  52% 52/100 [00:24<00:22,  2.16it/s]--------------------------------------------- Result 53 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "a \u001b[92mheady\u001b[0m , \u001b[92mbiting\u001b[0m , be-bop \u001b[92mride\u001b[0m through nighttime \u001b[92mmanhattan\u001b[0m , a loquacious videologue of the \u001b[92mmodern\u001b[0m \u001b[92mmale\u001b[0m and the \u001b[92mlengths\u001b[0m to which he'll go to \u001b[92mweave\u001b[0m a protective cocoon around his \u001b[92mown\u001b[0m \u001b[92mego\u001b[0m .\n",
            "\n",
            "a \u001b[91mdisturbed\u001b[0m , \u001b[91mtaunting\u001b[0m , be-bop \u001b[91mtrips\u001b[0m through nighttime \u001b[91mgramercy\u001b[0m , a loquacious videologue of the \u001b[91mupgraded\u001b[0m \u001b[91mguy\u001b[0m and the \u001b[91mlengthwise\u001b[0m to which he'll go to \u001b[91marmoured\u001b[0m a protective cocoon around his \u001b[91mproprietary\u001b[0m \u001b[91megos\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 41 / 1 / 11 / 53:  54% 54/100 [00:25<00:21,  2.15it/s]--------------------------------------------- Result 54 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (58%)\u001b[0m\n",
            "\n",
            "skin of man gets a few cheap shocks from its kids-in-peril theatrics , but it also \u001b[92mtaps\u001b[0m into the \u001b[92mprimal\u001b[0m \u001b[92mfears\u001b[0m of \u001b[92myoung\u001b[0m \u001b[92mpeople\u001b[0m trying to cope with the \u001b[92mmysterious\u001b[0m and brutal nature of adults .\n",
            "\n",
            "skin of man gets a few cheap shocks from its kids-in-peril theatrics , but it also \u001b[91mapplause\u001b[0m into the \u001b[91mrudimentary\u001b[0m \u001b[91mpanic\u001b[0m of \u001b[91mchildish\u001b[0m \u001b[91mcapita\u001b[0m trying to cope with the \u001b[91munclear\u001b[0m and brutal nature of adults .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 42 / 1 / 11 / 54:  54% 54/100 [00:25<00:21,  2.15it/s]--------------------------------------------- Result 55 ---------------------------------------------\n",
            "\u001b[92mPositive (72%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a \u001b[92mcool\u001b[0m distance from its material that is deliberately unsettling .\n",
            "\n",
            "the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a \u001b[91msuper\u001b[0m distance from its material that is deliberately unsettling .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 43 / 1 / 11 / 55:  55% 55/100 [00:25<00:20,  2.18it/s]--------------------------------------------- Result 56 ---------------------------------------------\n",
            "\u001b[92mPositive (88%)\u001b[0m --> \u001b[91mNegative (73%)\u001b[0m\n",
            "\n",
            "as \u001b[92mrefreshing\u001b[0m as a drink from a woodland stream .\n",
            "\n",
            "as \u001b[91mretrofitted\u001b[0m as a drink from a woodland stream .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 44 / 1 / 11 / 56:  56% 56/100 [00:25<00:19,  2.22it/s]--------------------------------------------- Result 57 ---------------------------------------------\n",
            "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (68%)\u001b[0m\n",
            "\n",
            "\u001b[92mwilliams\u001b[0m absolutely nails sy's queasy \u001b[92minfatuation\u001b[0m and overall \u001b[92mstrangeness\u001b[0m .\n",
            "\n",
            "\u001b[91mguillaume\u001b[0m absolutely nails sy's queasy \u001b[91mquash\u001b[0m and overall \u001b[91mclaustrophobia\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 45 / 1 / 11 / 57:  58% 58/100 [00:25<00:18,  2.28it/s]--------------------------------------------- Result 58 ---------------------------------------------\n",
            "\u001b[91mNegative (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "can i admit xxx is as deep as a petri dish and as well-characterized as a telephone book but still say it was a guilty pleasure ?\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 45 / 1 / 12 / 58:  58% 58/100 [00:25<00:18,  2.28it/s]--------------------------------------------- Result 59 ---------------------------------------------\n",
            "\u001b[92mPositive (84%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
            "\n",
            "while it's nothing we haven't seen before from murphy , i spy is still \u001b[92mfun\u001b[0m and enjoyable and so aggressively silly that it's more than a worthwhile effort .\n",
            "\n",
            "while it's nothing we haven't seen before from murphy , i spy is still \u001b[91mjoys\u001b[0m and enjoyable and so aggressively silly that it's more than a worthwhile effort .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 46 / 1 / 12 / 59:  59% 59/100 [00:25<00:17,  2.31it/s]--------------------------------------------- Result 60 ---------------------------------------------\n",
            "\u001b[92mPositive (62%)\u001b[0m --> \u001b[91mNegative (63%)\u001b[0m\n",
            "\n",
            "by the time it ends in a rush of sequins , flashbulbs , blaring brass and back-stabbing babes , it has said \u001b[92mplenty\u001b[0m about how show business has infiltrated every corner of society -- and not always for the better .\n",
            "\n",
            "by the time it ends in a rush of sequins , flashbulbs , blaring brass and back-stabbing babes , it has said \u001b[91mlots\u001b[0m about how show business has infiltrated every corner of society -- and not always for the better .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 47 / 1 / 12 / 60:  60% 60/100 [00:25<00:17,  2.33it/s]--------------------------------------------- Result 61 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "an \u001b[92mintimate\u001b[0m \u001b[92mcontemplation\u001b[0m of two marvelously messy lives .\n",
            "\n",
            "an \u001b[91msqueamish\u001b[0m \u001b[91mthink\u001b[0m of two marvelously messy lives .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 48 / 1 / 12 / 61:  62% 62/100 [00:25<00:15,  2.40it/s]--------------------------------------------- Result 62 ---------------------------------------------\n",
            "\u001b[91mNegative (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "rarely has skin looked as beautiful , desirable , even delectable , as it does in trouble every day .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 48 / 1 / 13 / 62:  62% 62/100 [00:25<00:15,  2.40it/s]--------------------------------------------- Result 63 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "this is one of those \u001b[92mrare\u001b[0m docs that \u001b[92mpaints\u001b[0m a \u001b[92mgrand\u001b[0m \u001b[92mpicture\u001b[0m of an \u001b[92mera\u001b[0m and \u001b[92mmakes\u001b[0m the journey feel like a \u001b[92mparty\u001b[0m .\n",
            "\n",
            "this is one of those \u001b[91mfew\u001b[0m docs that \u001b[91mrepainted\u001b[0m a \u001b[91msizable\u001b[0m \u001b[91mphoto\u001b[0m of an \u001b[91mtimes\u001b[0m and \u001b[91mai\u001b[0m the journey feel like a \u001b[91mportions\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 49 / 1 / 13 / 63:  63% 63/100 [00:26<00:15,  2.39it/s]--------------------------------------------- Result 64 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (68%)\u001b[0m\n",
            "\n",
            "\u001b[92mpoignant\u001b[0m if familiar story of a young person suspended between two cultures .\n",
            "\n",
            "\u001b[91mdreaded\u001b[0m if familiar story of a young person suspended between two cultures .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 50 / 1 / 13 / 64:  64% 64/100 [00:26<00:14,  2.42it/s]--------------------------------------------- Result 65 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (69%)\u001b[0m\n",
            "\n",
            "a \u001b[92mmetaphor\u001b[0m for a modern-day urban china searching for its identity .\n",
            "\n",
            "a \u001b[91mcliché\u001b[0m for a modern-day urban china searching for its identity .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 51 / 1 / 13 / 65:  66% 66/100 [00:26<00:13,  2.47it/s]--------------------------------------------- Result 66 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (64%)\u001b[0m\n",
            "\n",
            "for all its brooding quality , ash wednesday is \u001b[92msuspenseful\u001b[0m and ultimately unpredictable , with a \u001b[92msterling\u001b[0m \u001b[92mensemble\u001b[0m cast .\n",
            "\n",
            "for all its brooding quality , ash wednesday is \u001b[91moffbeat\u001b[0m and ultimately unpredictable , with a \u001b[91mlbs\u001b[0m \u001b[91mwhole\u001b[0m cast .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 52 / 1 / 13 / 66:  66% 66/100 [00:26<00:13,  2.47it/s]--------------------------------------------- Result 67 ---------------------------------------------\n",
            "\u001b[92mPositive (74%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "an odd drama set in the \u001b[92mworld\u001b[0m of lingerie models and bar dancers in the \u001b[92mmidwest\u001b[0m that held my interest \u001b[92mprecisely\u001b[0m because it didn't try to .\n",
            "\n",
            "an odd drama set in the \u001b[91morb\u001b[0m of lingerie models and bar dancers in the \u001b[91mdakotas\u001b[0m that held my interest \u001b[91maccurately\u001b[0m because it didn't try to .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 53 / 1 / 13 / 67:  67% 67/100 [00:26<00:13,  2.48it/s]--------------------------------------------- Result 68 ---------------------------------------------\n",
            "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "the film feels uncomfortably \u001b[92mreal\u001b[0m , its \u001b[92mlanguage\u001b[0m and locations bearing the unmistakable \u001b[92mstamp\u001b[0m of \u001b[92mauthority\u001b[0m .\n",
            "\n",
            "the film feels uncomfortably \u001b[91mveritable\u001b[0m , its \u001b[91mparlance\u001b[0m and locations bearing the unmistakable \u001b[91mtampon\u001b[0m of \u001b[91mpermission\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 54 / 1 / 13 / 68:  68% 68/100 [00:27<00:12,  2.50it/s]--------------------------------------------- Result 69 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (65%)\u001b[0m\n",
            "\n",
            "despite its \u001b[92mfaults\u001b[0m , gangs \u001b[92mexcels\u001b[0m in \u001b[92mspectacle\u001b[0m and \u001b[92mpacing\u001b[0m .\n",
            "\n",
            "despite its \u001b[91mpalaces\u001b[0m , gangs \u001b[91moverwhelms\u001b[0m in \u001b[91mlounges\u001b[0m and \u001b[91mstimulator\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 55 / 1 / 13 / 69:  70% 70/100 [00:27<00:11,  2.54it/s]--------------------------------------------- Result 70 ---------------------------------------------\n",
            "\u001b[92mPositive (69%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "\u001b[92mentertaining\u001b[0m despite its one-joke premise with the thesis that women from venus and men from mars can indeed get together .\n",
            "\n",
            "\u001b[91mamusement\u001b[0m despite its one-joke premise with the thesis that women from venus and men from mars can indeed get together .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 56 / 1 / 13 / 70:  70% 70/100 [00:27<00:11,  2.54it/s]--------------------------------------------- Result 71 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
            "\n",
            "a tightly directed , \u001b[92mhighly\u001b[0m professional \u001b[92mfilm\u001b[0m that's old-fashioned in all the best possible \u001b[92mways\u001b[0m .\n",
            "\n",
            "a tightly directed , \u001b[91moverly\u001b[0m professional \u001b[91mtheaters\u001b[0m that's old-fashioned in all the best possible \u001b[91mmethodology\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 57 / 1 / 13 / 71:  71% 71/100 [00:27<00:11,  2.54it/s]--------------------------------------------- Result 72 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it's dark but has wonderfully funny moments ; you care about the characters ; and the action and special effects are first-rate .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 57 / 2 / 13 / 72:  72% 72/100 [00:28<00:11,  2.51it/s]--------------------------------------------- Result 73 ---------------------------------------------\n",
            "\u001b[92mPositive (87%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "in visual fertility treasure planet rivals the \u001b[92mtop\u001b[0m japanese animations of \u001b[92mrecent\u001b[0m \u001b[92mvintage\u001b[0m .\n",
            "\n",
            "in visual fertility treasure planet rivals the \u001b[91mmain\u001b[0m japanese animations of \u001b[91mupdate\u001b[0m \u001b[91mgatherer\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 58 / 2 / 13 / 73:  74% 74/100 [00:29<00:10,  2.54it/s]--------------------------------------------- Result 74 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (79%)\u001b[0m\n",
            "\n",
            "\u001b[92menormously\u001b[0m \u001b[92menjoyable\u001b[0m , high-adrenaline \u001b[92mdocumentary\u001b[0m .\n",
            "\n",
            "\u001b[91mterribly\u001b[0m \u001b[91mcosy\u001b[0m , high-adrenaline \u001b[91mpaperwork\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 59 / 2 / 13 / 74:  74% 74/100 [00:29<00:10,  2.54it/s]--------------------------------------------- Result 75 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
            "\n",
            "buy is an \u001b[92maccomplished\u001b[0m \u001b[92mactress\u001b[0m , and this is a \u001b[92mbig\u001b[0m , \u001b[92mjuicy\u001b[0m \u001b[92mrole\u001b[0m .\n",
            "\n",
            "buy is an \u001b[91miend\u001b[0m \u001b[91mactresses\u001b[0m , and this is a \u001b[91mheavy\u001b[0m , \u001b[91mcrusty\u001b[0m \u001b[91mduties\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 60 / 2 / 13 / 75:  75% 75/100 [00:29<00:09,  2.54it/s]--------------------------------------------- Result 76 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "it \u001b[92mworks\u001b[0m its \u001b[92mmagic\u001b[0m with such \u001b[92mexuberance\u001b[0m and \u001b[92mpassion\u001b[0m that the film's length becomes a \u001b[92mpart\u001b[0m of its \u001b[92mfun\u001b[0m .\n",
            "\n",
            "it \u001b[91mfunctioned\u001b[0m its \u001b[91mpotions\u001b[0m with such \u001b[91melation\u001b[0m and \u001b[91mpastimes\u001b[0m that the film's length becomes a \u001b[91mfraction\u001b[0m of its \u001b[91mjoke\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 61 / 2 / 13 / 76:  76% 76/100 [00:30<00:09,  2.53it/s]--------------------------------------------- Result 77 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (74%)\u001b[0m\n",
            "\n",
            "\u001b[92mbeautifully\u001b[0m \u001b[92mcrafted\u001b[0m and \u001b[92mbrutally\u001b[0m \u001b[92mhonest\u001b[0m , promises offers an \u001b[92munexpected\u001b[0m \u001b[92mwindow\u001b[0m into the \u001b[92mcomplexities\u001b[0m of the \u001b[92mmiddle\u001b[0m \u001b[92meast\u001b[0m \u001b[92mstruggle\u001b[0m and into the \u001b[92mhumanity\u001b[0m of its \u001b[92mpeople\u001b[0m .\n",
            "\n",
            "\u001b[91mimpossibly\u001b[0m \u001b[91mfabricated\u001b[0m and \u001b[91mhastily\u001b[0m \u001b[91mfrankly\u001b[0m , promises offers an \u001b[91munwanted\u001b[0m \u001b[91mbeaker\u001b[0m into the \u001b[91mcomplicate\u001b[0m of the \u001b[91maverage\u001b[0m \u001b[91meastern\u001b[0m \u001b[91mfight\u001b[0m and into the \u001b[91mhumans\u001b[0m of its \u001b[91mcapita\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 62 / 2 / 13 / 77:  78% 78/100 [00:31<00:08,  2.51it/s]--------------------------------------------- Result 78 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
            "\n",
            "an old-fashioned but emotionally \u001b[92mstirring\u001b[0m \u001b[92madventure\u001b[0m tale of the kind they \u001b[92mrarely\u001b[0m make anymore .\n",
            "\n",
            "an old-fashioned but emotionally \u001b[91mtwitching\u001b[0m \u001b[91mitinerary\u001b[0m tale of the kind they \u001b[91mthinly\u001b[0m make anymore .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 63 / 2 / 13 / 78:  78% 78/100 [00:31<00:08,  2.51it/s]--------------------------------------------- Result 79 ---------------------------------------------\n",
            "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (79%)\u001b[0m\n",
            "\n",
            "charlotte sometimes is a \u001b[92mgem\u001b[0m . it's always \u001b[92menthralling\u001b[0m .\n",
            "\n",
            "charlotte sometimes is a \u001b[91mbling\u001b[0m . it's always \u001b[91mbreathless\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 64 / 2 / 13 / 79:  79% 79/100 [00:31<00:08,  2.52it/s]--------------------------------------------- Result 80 ---------------------------------------------\n",
            "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "in my opinion , analyze that is not as funny or entertaining as analyze this , but it is a respectable sequel .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 64 / 3 / 13 / 80:  80% 80/100 [00:31<00:07,  2.50it/s]--------------------------------------------- Result 81 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "a \u001b[92mremarkable\u001b[0m film by bernard rose .\n",
            "\n",
            "a \u001b[91munpaid\u001b[0m film by bernard rose .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 65 / 3 / 13 / 81:  82% 82/100 [00:32<00:07,  2.55it/s]--------------------------------------------- Result 82 ---------------------------------------------\n",
            "\u001b[91mNegative (71%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "zhuangzhuang creates delicate balance of style , text , and subtext that's so simple and precise that anything discordant would topple the balance , but against all odds , nothing does .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 65 / 3 / 14 / 82:  82% 82/100 [00:32<00:07,  2.55it/s]--------------------------------------------- Result 83 ---------------------------------------------\n",
            "\u001b[92mPositive (86%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
            "\n",
            "a much more \u001b[92msuccessful\u001b[0m translation than its most \u001b[92mfamous\u001b[0m \u001b[92mprevious\u001b[0m \u001b[92mfilm\u001b[0m adaptation , writer-director anthony friedman's similarly updated 1970 british \u001b[92mproduction\u001b[0m .\n",
            "\n",
            "a much more \u001b[91mavail\u001b[0m translation than its most \u001b[91minfamous\u001b[0m \u001b[91melderly\u001b[0m \u001b[91mmovie\u001b[0m adaptation , writer-director anthony friedman's similarly updated 1970 british \u001b[91mmanufactured\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 66 / 3 / 14 / 83:  83% 83/100 [00:32<00:06,  2.54it/s]--------------------------------------------- Result 84 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "an \u001b[92moriginal\u001b[0m and \u001b[92mhighly\u001b[0m cerebral \u001b[92mexamination\u001b[0m of the \u001b[92mpsychopathic\u001b[0m \u001b[92mmind\u001b[0m\n",
            "\n",
            "an \u001b[91mpreliminary\u001b[0m and \u001b[91mexcessively\u001b[0m cerebral \u001b[91mverify\u001b[0m of the \u001b[91mobsessed\u001b[0m \u001b[91mbother\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 67 / 3 / 14 / 84:  84% 84/100 [00:33<00:06,  2.53it/s]--------------------------------------------- Result 85 ---------------------------------------------\n",
            "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "michel piccoli's \u001b[92mmoving\u001b[0m \u001b[92mperformance\u001b[0m is this \u001b[92mfilms\u001b[0m reason for being .\n",
            "\n",
            "michel piccoli's \u001b[91mdisplaced\u001b[0m \u001b[91mimplementation\u001b[0m is this \u001b[91mflick\u001b[0m reason for being .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 68 / 3 / 14 / 85:  86% 86/100 [00:33<00:05,  2.54it/s]--------------------------------------------- Result 86 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "a captivating and intimate study about dying and loving . . .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 68 / 4 / 14 / 86:  86% 86/100 [00:33<00:05,  2.54it/s]--------------------------------------------- Result 87 ---------------------------------------------\n",
            "\u001b[92mPositive (56%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "this is an \u001b[92melegantly\u001b[0m balanced movie -- every member of the ensemble has something fascinating to do -- that doesn't reveal even a hint of artifice .\n",
            "\n",
            "this is an \u001b[91mstylishly\u001b[0m balanced movie -- every member of the ensemble has something fascinating to do -- that doesn't reveal even a hint of artifice .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 69 / 4 / 14 / 87:  87% 87/100 [00:33<00:05,  2.56it/s]--------------------------------------------- Result 88 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "[\u001b[92mgrant\u001b[0m] goes beyond his usual fluttering and \u001b[92mstammering\u001b[0m and \u001b[92mcaptures\u001b[0m the \u001b[92msoul\u001b[0m of a \u001b[92mman\u001b[0m in pain who gradually comes to recognize it and deal with it .\n",
            "\n",
            "[\u001b[91msubsides\u001b[0m] goes beyond his usual fluttering and \u001b[91mstuttered\u001b[0m and \u001b[91mnabbed\u001b[0m the \u001b[91mames\u001b[0m of a \u001b[91mdude\u001b[0m in pain who gradually comes to recognize it and deal with it .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 70 / 4 / 14 / 88:  88% 88/100 [00:34<00:04,  2.56it/s]--------------------------------------------- Result 89 ---------------------------------------------\n",
            "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "a high-spirited buddy movie about the reunion of berlin anarchists who face arrest 15 years after their crime .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 70 / 5 / 14 / 89:  90% 90/100 [00:35<00:03,  2.56it/s]--------------------------------------------- Result 90 ---------------------------------------------\n",
            "\u001b[91mNegative (68%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "about the best thing you could say about narc is that it's a rock-solid little genre picture . whether you like it or not is basically a matter of taste .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 70 / 5 / 15 / 90:  90% 90/100 [00:35<00:03,  2.56it/s]--------------------------------------------- Result 91 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "an \u001b[92minvolving\u001b[0m , \u001b[92minspirational\u001b[0m \u001b[92mdrama\u001b[0m that sometimes falls prey to its sob-story trappings .\n",
            "\n",
            "an \u001b[91mconsists\u001b[0m , \u001b[91mincite\u001b[0m \u001b[91mcatastrophic\u001b[0m that sometimes falls prey to its sob-story trappings .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 71 / 5 / 15 / 91:  91% 91/100 [00:35<00:03,  2.57it/s]--------------------------------------------- Result 92 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
            "\n",
            "some of the most \u001b[92minventive\u001b[0m silliness you are likely to \u001b[92mwitness\u001b[0m in a movie theatre for some \u001b[92mtime\u001b[0m .\n",
            "\n",
            "some of the most \u001b[91mcontrivance\u001b[0m silliness you are likely to \u001b[91mevidence\u001b[0m in a movie theatre for some \u001b[91mminute\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 72 / 5 / 15 / 92:  92% 92/100 [00:35<00:03,  2.58it/s]--------------------------------------------- Result 93 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "canadian filmmaker gary burns' inventive and mordantly humorous take on the soullessness of work in the city .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 72 / 6 / 15 / 93:  94% 94/100 [00:36<00:02,  2.56it/s]--------------------------------------------- Result 94 ---------------------------------------------\n",
            "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "a rollicking \u001b[92mride\u001b[0m , with jaw-dropping action sequences , \u001b[92mstriking\u001b[0m villains , a \u001b[92mgorgeous\u001b[0m \u001b[92mcolor\u001b[0m palette , astounding technology , \u001b[92mstirring\u001b[0m \u001b[92mmusic\u001b[0m and a boffo last hour that \u001b[92mleads\u001b[0m up to a strangely sinister \u001b[92mhappy\u001b[0m ending .\n",
            "\n",
            "a rollicking \u001b[91mwrinkle\u001b[0m , with jaw-dropping action sequences , \u001b[91mwhopping\u001b[0m villains , a \u001b[91msuper\u001b[0m \u001b[91msmudged\u001b[0m palette , astounding technology , \u001b[91mirate\u001b[0m \u001b[91mvocalist\u001b[0m and a boffo last hour that \u001b[91mculminating\u001b[0m up to a strangely sinister \u001b[91moptimistic\u001b[0m ending .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 73 / 6 / 15 / 94:  94% 94/100 [00:36<00:02,  2.56it/s]--------------------------------------------- Result 95 ---------------------------------------------\n",
            "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
            "\n",
            "everyone's insecure in lovely and \u001b[92mamazing\u001b[0m , a \u001b[92mpoignant\u001b[0m and wryly \u001b[92mamusing\u001b[0m \u001b[92mfilm\u001b[0m about \u001b[92mmothers\u001b[0m , \u001b[92mdaughters\u001b[0m and their relationships .\n",
            "\n",
            "everyone's insecure in lovely and \u001b[91mfunky\u001b[0m , a \u001b[91mdepressing\u001b[0m and wryly \u001b[91mgoofy\u001b[0m \u001b[91mtheaters\u001b[0m about \u001b[91mmoms\u001b[0m , \u001b[91mgals\u001b[0m and their relationships .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 74 / 6 / 15 / 95:  95% 95/100 [00:37<00:01,  2.55it/s]--------------------------------------------- Result 96 ---------------------------------------------\n",
            "\u001b[92mPositive (61%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "the closest thing to the \u001b[92mexperience\u001b[0m of space travel\n",
            "\n",
            "the closest thing to the \u001b[91mpilot\u001b[0m of space travel\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 75 / 6 / 15 / 96:  96% 96/100 [00:37<00:01,  2.57it/s]--------------------------------------------- Result 97 ---------------------------------------------\n",
            "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (89%)\u001b[0m\n",
            "\n",
            "full of \u001b[92msurprises\u001b[0m .\n",
            "\n",
            "full of \u001b[91mstupor\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 76 / 6 / 15 / 97:  98% 98/100 [00:37<00:00,  2.60it/s]--------------------------------------------- Result 98 ---------------------------------------------\n",
            "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (57%)\u001b[0m\n",
            "\n",
            "connoisseurs of chinese film will be \u001b[92mpleased\u001b[0m to discover that tian's meticulous \u001b[92mtalent\u001b[0m has not \u001b[92mwithered\u001b[0m during his enforced hiatus .\n",
            "\n",
            "connoisseurs of chinese film will be \u001b[91mravi\u001b[0m to discover that tian's meticulous \u001b[91mskilled\u001b[0m has not \u001b[91mripened\u001b[0m during his enforced hiatus .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 77 / 6 / 15 / 98:  98% 98/100 [00:37<00:00,  2.60it/s]--------------------------------------------- Result 99 ---------------------------------------------\n",
            "\u001b[92mPositive (88%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "if you can push on through the slow spots , you'll be \u001b[92mrewarded\u001b[0m with some \u001b[92mfine\u001b[0m \u001b[92macting\u001b[0m .\n",
            "\n",
            "if you can push on through the slow spots , you'll be \u001b[91mmet\u001b[0m with some \u001b[91msumptuous\u001b[0m \u001b[91minterim\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 78 / 6 / 15 / 99:  99% 99/100 [00:37<00:00,  2.61it/s]--------------------------------------------- Result 100 ---------------------------------------------\n",
            "\u001b[92mPositive (89%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
            "\n",
            "an unusually dry-eyed , even analytical \u001b[92mapproach\u001b[0m to \u001b[92mmaterial\u001b[0m that is generally played for maximum \u001b[92mmoisture\u001b[0m .\n",
            "\n",
            "an unusually dry-eyed , even analytical \u001b[91msignifies\u001b[0m to \u001b[91mhardware\u001b[0m that is generally played for maximum \u001b[91mhumidity\u001b[0m .\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 79 / 6 / 15 / 100: 100% 100/100 [00:38<00:00,  2.63it/s]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 79     |\n",
            "| Number of failed attacks:     | 6      |\n",
            "| Number of skipped attacks:    | 15     |\n",
            "| Original accuracy:            | 85.0%  |\n",
            "| Accuracy under attack:        | 6.0%   |\n",
            "| Attack success rate:          | 92.94% |\n",
            "| Average perturbed word %:     | 22.69% |\n",
            "| Average num. words per input: | 18.45  |\n",
            "| Avg num queries:              | 123.19 |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ],
      "source": [
        "!textattack attack --recipe textfooler --num-examples 100 --model ./outputs/2025-10-12-22-20-48-558446/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pldN3i5PsGC1"
      },
      "source": [
        "Robustness improved after training: robust accuracy rose from 2% to 6%, the attack success rate dropped from ~97.7% to ~92.9%, and the attacker needed more queries (≈75 → 123) and larger perturbations (≈13.7% → 22.7%) to succeed. Clean accuracy stayed about the same (86% → 85%), so the gain came specifically from increased resistance to TextFooler.\n",
        "\n",
        "To sum up all, adversarial training made the model harder to fool while preserving clean performance.\n",
        "Since these gains came from only a small number of epochs with restricted training settings, the robustness could likely improve even further by removing those constraints and training over more epochs."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ta-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
